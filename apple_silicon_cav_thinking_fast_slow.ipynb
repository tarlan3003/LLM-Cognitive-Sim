{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Concept Activation Vectors (CAVs) for \"Thinking Fast and Slow\"\n",
    "\n",
    "This notebook demonstrates how to implement Concept Activation Vectors (CAVs) to replicate cognitive theories from Daniel Kahneman's \"Thinking Fast and Slow\". We'll focus on implementing System 1 (fast thinking) vs System 2 (slow thinking) and various cognitive biases/heuristics described in the book.\n",
    "\n",
    "## Overview\n",
    "\n",
    "Concept Activation Vectors (CAVs) are a technique for steering language model behavior by manipulating internal neural activations. In this notebook, we'll:\n",
    "\n",
    "1. Set up the environment and load a language model\n",
    "2. Create a CAV implementation for manipulating model behavior\n",
    "3. Train CAVs for System 1 and System 2 thinking patterns\n",
    "4. Train CAVs for specific cognitive biases from the book\n",
    "5. Test the CAVs on examples from \"Thinking Fast and Slow\"\n",
    "6. Evaluate the results\n",
    "\n",
    "Let's get started!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Dependencies\n",
    "\n",
    "First, let's install the necessary dependencies and set up for Apple Silicon compatibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apple Silicon (M1/M2/M3) compatibility settings\n",
    "# IMPORTANT: Run this cell first, before importing any other libraries\n",
    "import os\n",
    "\n",
    "# Completely disable MPS (Metal Performance Shaders)\n",
    "os.environ[\"PYTORCH_ENABLE_MPS_FALLBACK\"] = \"1\"\n",
    "os.environ[\"PYTORCH_MPS_HIGH_WATERMARK_RATIO\"] = \"0.0\"\n",
    "os.environ[\"PYTORCH_NO_MPS\"] = \"1\"  # This is critical - forces PyTorch to ignore MPS\n",
    "\n",
    "# Install required packages if needed\n",
    "# !pip install torch transformers datasets numpy matplotlib scikit-learn tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jchen/fine-tuning/LLM-Cognitive-Sim/.venv/lib/python3.12/site-packages/torch/_subclasses/functional_tensor.py:276: UserWarning: Failed to initialize NumPy: No module named 'numpy' (Triggered internally at /pytorch/torch/csrc/utils/tensor_numpy.cpp:81.)\n",
      "  cpu = _conversion_method_template(device=torch.device(\"cpu\"))\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'numpy'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtorch\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mmatplotlib\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mpyplot\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mplt\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoModelForCausalLM, AutoTokenizer\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'numpy'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from tqdm.notebook import tqdm\n",
    "import json\n",
    "import random\n",
    "from typing import List, Dict, Tuple, Optional, Union, Any\n",
    "\n",
    "# Force CPU for all PyTorch operations\n",
    "if hasattr(torch, \"_C\") and hasattr(torch._C, \"_set_default_device\"):\n",
    "    torch._C._set_default_device(\"cpu\")\n",
    "device = \"cpu\"\n",
    "\n",
    "# Double-check we're not using MPS\n",
    "if hasattr(torch.backends, \"mps\"):\n",
    "    print(f\"MPS available: {torch.backends.mps.is_available()}\")\n",
    "    if torch.backends.mps.is_available():\n",
    "        print(\"WARNING: MPS is still available despite disabling it. Forcing CPU usage.\")\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "print(f\"Using device: {device} (forced for Apple Silicon compatibility)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load a Language Model\n",
    "\n",
    "We'll use a smaller open-source model that allows us to access and manipulate internal activations. For this demonstration, we'll use a smaller model like OPT-1.3B or GPT-2, but you can replace it with any model you prefer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading facebook/opt-1.3b...\n",
      "Model device: cpu\n",
      "Model loaded successfully!\n"
     ]
    }
   ],
   "source": [
    "# Define model name - using a smaller model that's more accessible\n",
    "model_name = \"facebook/opt-1.3b\"  # Alternative options: \"gpt2\", \"EleutherAI/pythia-1.4b\", \"TinyLlama/TinyLlama-1.1B-Chat-v1.0\"\n",
    "\n",
    "# Load model and tokenizer\n",
    "print(f\"Loading {model_name}...\")\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_name,\n",
    "    torch_dtype=torch.float32,  # Use float32 for CPU\n",
    "    device_map=None  # Don't use device_map with CPU\n",
    ")\n",
    "\n",
    "# Explicitly move model to CPU\n",
    "model = model.to(\"cpu\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
    "\n",
    "# Verify model is on CPU\n",
    "print(f\"Model device: {next(model.parameters()).device}\")\n",
    "assert str(next(model.parameters()).device) == \"cpu\", \"Model must be on CPU\"\n",
    "print(\"Model loaded successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Concept Activation Vectors Implementation\n",
    "\n",
    "Now, let's implement the core CAV functionality. This includes:\n",
    "- Registering hooks to access model activations\n",
    "- Collecting activations for contrastive examples\n",
    "- Training classifiers to identify concept directions\n",
    "- Applying steering during generation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConceptActivationVectors:\n",
    "    \"\"\"\n",
    "    Implementation of Concept Activation Vectors (CAVs) for steering LLM behavior.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Initialize the CAV implementation with a specified model.\n",
    "        \n",
    "        Args:\n",
    "            model: Hugging Face model\n",
    "            tokenizer: Hugging Face tokenizer\n",
    "            device: Device to run the model on (cuda or cpu)\n",
    "        \"\"\"\n",
    "        self.model = model\n",
    "        self.tokenizer = tokenizer\n",
    "        self.device = \"cpu\"  # Force CPU for Apple Silicon compatibility\n",
    "        \n",
    "        # Dictionary to store concept vectors for different concepts\n",
    "        self.concept_vectors = {}\n",
    "        \n",
    "        # Hooks for accessing activations\n",
    "        self.hooks = []\n",
    "        self.activation_storage = {}\n",
    "        \n",
    "        # Verify model is on CPU\n",
    "        assert str(next(model.parameters()).device) == \"cpu\", \"Model must be on CPU\"\n",
    "    \n",
    "    def _register_hooks(self, layers):\n",
    "        \"\"\"\n",
    "        Register hooks to capture activations from specified layers.\n",
    "        \n",
    "        Args:\n",
    "            layers: List of layer indices to capture activations from\n",
    "        \"\"\"\n",
    "        # Remove any existing hooks\n",
    "        self._remove_hooks()\n",
    "        \n",
    "        # Register new hooks\n",
    "        for layer_idx in layers:\n",
    "            try:\n",
    "                # Access transformer layers (implementation depends on model architecture)\n",
    "                if \"llama\" in str(type(self.model)).lower():\n",
    "                    layer = self.model.model.layers[layer_idx]\n",
    "                elif \"mistral\" in str(type(self.model)).lower():\n",
    "                    layer = self.model.model.layers[layer_idx]\n",
    "                elif \"opt\" in str(type(self.model)).lower():\n",
    "                    layer = self.model.model.decoder.layers[layer_idx]\n",
    "                elif \"gpt2\" in str(type(self.model)).lower():\n",
    "                    layer = self.model.transformer.h[layer_idx]\n",
    "                else:\n",
    "                    # Generic approach for other models\n",
    "                    layer = list(self.model.modules())[layer_idx]\n",
    "                \n",
    "                # Define hook function to store activations\n",
    "                def get_hook_fn(layer_id):\n",
    "                    def hook_fn(module, input, output):\n",
    "                        # Handle case where output is a tuple (common in transformer models)\n",
    "                        try:\n",
    "                            if isinstance(output, tuple):\n",
    "                                # Usually the first element contains the hidden states\n",
    "                                self.activation_storage[layer_id] = output[0].detach().to(\"cpu\")\n",
    "                            else:\n",
    "                                # Original code for when output is a tensor\n",
    "                                self.activation_storage[layer_id] = output.detach().to(\"cpu\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error in hook for layer {layer_id}: {e}\")\n",
    "                            print(f\"Output type: {type(output)}\")\n",
    "                            if isinstance(output, tuple):\n",
    "                                print(f\"Tuple length: {len(output)}\")\n",
    "                    return hook_fn\n",
    "                \n",
    "                # Register the hook\n",
    "                hook = layer.register_forward_hook(get_hook_fn(layer_idx))\n",
    "                self.hooks.append(hook)\n",
    "                print(f\"Registered hook for layer {layer_idx}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error registering hook for layer {layer_idx}: {e}\")\n",
    "    \n",
    "    def _remove_hooks(self):\n",
    "        \"\"\"Remove all registered hooks.\"\"\"\n",
    "        for hook in self.hooks:\n",
    "            hook.remove()\n",
    "        self.hooks = []\n",
    "        self.activation_storage = {}\n",
    "        print(\"Removed all hooks\")\n",
    "    \n",
    "    def collect_activations(self, prompts, layers):\n",
    "        \"\"\"\n",
    "        Collect activations from the model for a list of prompts.\n",
    "        \n",
    "        Args:\n",
    "            prompts: List of text prompts\n",
    "            layers: List of layer indices to collect activations from\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping layer indices to lists of activation tensors\n",
    "        \"\"\"\n",
    "        self._register_hooks(layers)\n",
    "        activations = {layer: [] for layer in layers}\n",
    "        \n",
    "        for prompt in tqdm(prompts, desc=\"Collecting activations\"):\n",
    "            # Ensure inputs are on CPU\n",
    "            inputs = self.tokenizer(prompt, return_tensors=\"pt\")\n",
    "            inputs = {k: v.to(\"cpu\") for k, v in inputs.items()}\n",
    "            \n",
    "            # Run the model in evaluation mode\n",
    "            self.model.eval()\n",
    "            with torch.no_grad():\n",
    "                try:\n",
    "                    self.model(**inputs)\n",
    "                    \n",
    "                    # Store activations\n",
    "                    for layer in layers:\n",
    "                        if layer in self.activation_storage:\n",
    "                            # Store a copy of the activation to avoid reference issues\n",
    "                            activations[layer].append(self.activation_storage[layer].clone())\n",
    "                        else:\n",
    "                            print(f\"Warning: No activation stored for layer {layer}\")\n",
    "                except Exception as e:\n",
    "                    print(f\"Error running model for prompt '{prompt[:30]}...': {e}\")\n",
    "        \n",
    "        self._remove_hooks()\n",
    "        return activations\n",
    "    \n",
    "    def train_concept_vector(self, concept_name, positive_prompts, negative_prompts, layers):\n",
    "        \"\"\"\n",
    "        Train a concept activation vector using contrastive examples.\n",
    "        \n",
    "        Args:\n",
    "            concept_name: Name of the concept (e.g., \"system1_thinking\", \"anchoring_bias\")\n",
    "            positive_prompts: Prompts that exhibit the concept\n",
    "            negative_prompts: Prompts that don't exhibit the concept\n",
    "            layers: List of layer indices to train CAVs for\n",
    "            \n",
    "        Returns:\n",
    "            Dictionary mapping layer indices to concept vectors\n",
    "        \"\"\"\n",
    "        print(f\"Training concept vector for '{concept_name}'...\")\n",
    "        \n",
    "        # Collect activations for positive and negative examples\n",
    "        positive_activations = self.collect_activations(positive_prompts, layers)\n",
    "        negative_activations = self.collect_activations(negative_prompts, layers)\n",
    "        \n",
    "        # Train a classifier for each layer\n",
    "        concept_vectors = {}\n",
    "        \n",
    "        for layer in layers:\n",
    "            if layer not in positive_activations or not positive_activations[layer] or \\\n",
    "               layer not in negative_activations or not negative_activations[layer]:\n",
    "                print(f\"Skipping layer {layer} due to missing activations\")\n",
    "                continue\n",
    "                \n",
    "            # Prepare training data\n",
    "            try:\n",
    "                # Debug activation shapes\n",
    "                print(f\"Layer {layer} activation shapes:\")\n",
    "                for i, act in enumerate(positive_activations[layer]):\n",
    "                    print(f\"  Positive example {i}: {act.shape}\")\n",
    "                for i, act in enumerate(negative_activations[layer]):\n",
    "                    print(f\"  Negative example {i}: {act.shape}\")\n",
    "                \n",
    "                # Use mean pooling to get fixed-size representations\n",
    "                # This avoids dimension mismatch issues\n",
    "                X_positive = torch.stack([act.mean(dim=1).squeeze() for act in positive_activations[layer]]).cpu().numpy()\n",
    "                X_negative = torch.stack([act.mean(dim=1).squeeze() for act in negative_activations[layer]]).cpu().numpy()\n",
    "                \n",
    "                print(f\"After pooling - X_positive shape: {X_positive.shape}, X_negative shape: {X_negative.shape}\")\n",
    "                \n",
    "                X = np.vstack([X_positive, X_negative])\n",
    "                y = np.array([1] * len(positive_prompts) + [0] * len(negative_prompts))\n",
    "                \n",
    "                # Train logistic regression classifier\n",
    "                classifier = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
    "                classifier.fit(X, y)\n",
    "                \n",
    "                # Extract the concept vector (normal to the decision boundary)\n",
    "                concept_vector = classifier.coef_[0]\n",
    "                \n",
    "                # Normalize the vector\n",
    "                concept_vector = concept_vector / np.linalg.norm(concept_vector)\n",
    "                \n",
    "                # Store the concept vector\n",
    "                concept_vectors[layer] = torch.tensor(concept_vector, dtype=torch.float32).to(\"cpu\")\n",
    "                \n",
    "                print(f\"  Layer {layer}: Classifier accuracy = {classifier.score(X, y):.4f}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error training classifier for layer {layer}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        # Store the concept vectors\n",
    "        self.concept_vectors[concept_name] = concept_vectors\n",
    "        \n",
    "        return concept_vectors\n",
    "    \n",
    "    def apply_steering(self, prompt, concept_name, layers, steering_strength=1.0, max_tokens=100):\n",
    "        \"\"\"\n",
    "        Apply concept steering during generation.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Input prompt\n",
    "            concept_name: Name of the concept to steer towards/away from\n",
    "            layers: List of layer indices to apply steering to\n",
    "            steering_strength: Strength of steering (positive for enhancing, negative for suppressing)\n",
    "            max_tokens: Maximum number of tokens to generate\n",
    "            \n",
    "        Returns:\n",
    "            Generated text with concept steering applied\n",
    "        \"\"\"\n",
    "        if concept_name not in self.concept_vectors:\n",
    "            raise ValueError(f\"Concept '{concept_name}' not found. Train it first.\")\n",
    "        \n",
    "        # Ensure we have concept vectors for all specified layers\n",
    "        valid_layers = []\n",
    "        for layer in layers:\n",
    "            if layer in self.concept_vectors[concept_name]:\n",
    "                valid_layers.append(layer)\n",
    "            else:\n",
    "                print(f\"Warning: No concept vector for layer {layer} and concept '{concept_name}'. Skipping.\")\n",
    "        \n",
    "        if not valid_layers:\n",
    "            raise ValueError(f\"No valid layers found for concept '{concept_name}'\")\n",
    "        \n",
    "        # Tokenize the prompt\n",
    "        inputs = self.tokenizer(prompt, return_tensors=\"pt\").to(\"cpu\")\n",
    "        \n",
    "        # Define a forward hook that applies steering\n",
    "        def steering_hook(layer_idx, module, input, output):\n",
    "            try:\n",
    "                # Get the concept vector for this layer\n",
    "                concept_vector = self.concept_vectors[concept_name][layer_idx].to(\"cpu\")\n",
    "                \n",
    "                # Handle case where output is a tuple\n",
    "                if isinstance(output, tuple):\n",
    "                    # Get the first element (usually the hidden states)\n",
    "                    original_output = output[0]\n",
    "                    \n",
    "                    # Use mean pooling to match dimensions\n",
    "                    # Reshape the concept vector to match the output shape\n",
    "                    hidden_dim = original_output.size(-1)\n",
    "                    if concept_vector.size(0) != hidden_dim:\n",
    "                        # Resize concept vector if dimensions don't match\n",
    "                        print(f\"Resizing concept vector from {concept_vector.size(0)} to {hidden_dim}\")\n",
    "                        if concept_vector.size(0) > hidden_dim:\n",
    "                            concept_vector = concept_vector[:hidden_dim]\n",
    "                        else:\n",
    "                            # Pad with zeros if concept vector is smaller\n",
    "                            padding = torch.zeros(hidden_dim - concept_vector.size(0), device=\"cpu\")\n",
    "                            concept_vector = torch.cat([concept_vector, padding])\n",
    "                    \n",
    "                    # Reshape for broadcasting\n",
    "                    reshaped_vector = concept_vector.reshape(1, 1, -1)\n",
    "                    \n",
    "                    # Apply steering\n",
    "                    modified_output = original_output + steering_strength * reshaped_vector\n",
    "                    \n",
    "                    # Return a new tuple with the modified first element\n",
    "                    return (modified_output,) + output[1:]\n",
    "                else:\n",
    "                    # Original code for when output is a tensor\n",
    "                    hidden_dim = output.size(-1)\n",
    "                    if concept_vector.size(0) != hidden_dim:\n",
    "                        # Resize concept vector if dimensions don't match\n",
    "                        print(f\"Resizing concept vector from {concept_vector.size(0)} to {hidden_dim}\")\n",
    "                        if concept_vector.size(0) > hidden_dim:\n",
    "                            concept_vector = concept_vector[:hidden_dim]\n",
    "                        else:\n",
    "                            # Pad with zeros if concept vector is smaller\n",
    "                            padding = torch.zeros(hidden_dim - concept_vector.size(0), device=\"cpu\")\n",
    "                            concept_vector = torch.cat([concept_vector, padding])\n",
    "                    \n",
    "                    reshaped_vector = concept_vector.reshape(1, 1, -1)\n",
    "                    modified_output = output + steering_strength * reshaped_vector\n",
    "                    return modified_output\n",
    "            except Exception as e:\n",
    "                print(f\"Error in steering hook for layer {layer_idx}: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                return output  # Return original output on error\n",
    "        \n",
    "        # Register steering hooks\n",
    "        hooks = []\n",
    "        for layer_idx in valid_layers:\n",
    "            try:\n",
    "                if \"llama\" in str(type(self.model)).lower():\n",
    "                    layer = self.model.model.layers[layer_idx]\n",
    "                elif \"mistral\" in str(type(self.model)).lower():\n",
    "                    layer = self.model.model.layers[layer_idx]\n",
    "                elif \"opt\" in str(type(self.model)).lower():\n",
    "                    layer = self.model.model.decoder.layers[layer_idx]\n",
    "                elif \"gpt2\" in str(type(self.model)).lower():\n",
    "                    layer = self.model.transformer.h[layer_idx]\n",
    "                else:\n",
    "                    layer = list(self.model.modules())[layer_idx]\n",
    "                \n",
    "                hook = layer.register_forward_hook(\n",
    "                    lambda module, input, output, layer_idx=layer_idx: \n",
    "                    steering_hook(layer_idx, module, input, output)\n",
    "                )\n",
    "                hooks.append(hook)\n",
    "                print(f\"Registered steering hook for layer {layer_idx}\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error registering steering hook for layer {layer_idx}: {e}\")\n",
    "        \n",
    "        # Generate text with steering applied\n",
    "        self.model.eval()\n",
    "        with torch.no_grad():\n",
    "            try:\n",
    "                outputs = self.model.generate(\n",
    "                    inputs.input_ids,\n",
    "                    max_new_tokens=max_tokens,\n",
    "                    do_sample=True,\n",
    "                    temperature=0.7,\n",
    "                    top_p=0.9\n",
    "                )\n",
    "            except Exception as e:\n",
    "                print(f\"Error during generation: {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "                # Remove hooks before re-raising\n",
    "                for hook in hooks:\n",
    "                    hook.remove()\n",
    "                raise\n",
    "        \n",
    "        # Remove hooks\n",
    "        for hook in hooks:\n",
    "            hook.remove()\n",
    "        \n",
    "        # Decode the generated text\n",
    "        generated_text = self.tokenizer.decode(outputs[0], skip_special_tokens=True)\n",
    "        \n",
    "        return generated_text\n",
    "    \n",
    "    def save_concept_vectors(self, filepath):\n",
    "        \"\"\"Save trained concept vectors to a file.\"\"\"\n",
    "        # Convert tensors to numpy arrays for saving\n",
    "        serializable_vectors = {}\n",
    "        for concept, layers in self.concept_vectors.items():\n",
    "            serializable_vectors[concept] = {\n",
    "                str(layer): vector.cpu().numpy().tolist() \n",
    "                for layer, vector in layers.items()\n",
    "            }\n",
    "        \n",
    "        with open(filepath, 'w') as f:\n",
    "            json.dump(serializable_vectors, f)\n",
    "        \n",
    "        print(f\"Concept vectors saved to {filepath}\")\n",
    "    \n",
    "    def load_concept_vectors(self, filepath):\n",
    "        \"\"\"Load trained concept vectors from a file.\"\"\"\n",
    "        with open(filepath, 'r') as f:\n",
    "            serializable_vectors = json.load(f)\n",
    "        \n",
    "        # Convert back to tensors\n",
    "        self.concept_vectors = {}\n",
    "        for concept, layers in serializable_vectors.items():\n",
    "            self.concept_vectors[concept] = {\n",
    "                int(layer): torch.tensor(vector, dtype=torch.float32).to(\"cpu\")\n",
    "                for layer, vector in layers.items()\n",
    "            }\n",
    "        \n",
    "        print(f\"Loaded concept vectors for: {list(self.concept_vectors.keys())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Thinking Fast and Slow Implementation\n",
    "\n",
    "Now, let's create a specialized class for implementing concepts from \"Thinking Fast and Slow\" using CAVs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ThinkingFastSlowCAV:\n",
    "    \"\"\"\n",
    "    Implementation of Concept Activation Vectors specifically for replicating\n",
    "    theories from \"Thinking Fast and Slow\" by Daniel Kahneman.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, model, tokenizer, device=\"cpu\"):\n",
    "        \"\"\"\n",
    "        Initialize the implementation.\n",
    "        \n",
    "        Args:\n",
    "            model: Hugging Face model\n",
    "            tokenizer: Hugging Face tokenizer\n",
    "            device: Device to run the model on (cuda or cpu)\n",
    "        \"\"\"\n",
    "        # Force CPU for Apple Silicon compatibility\n",
    "        self.device = \"cpu\"\n",
    "        self.cav = ConceptActivationVectors(model, tokenizer, self.device)\n",
    "        \n",
    "        # Create data directory if it doesn't exist\n",
    "        os.makedirs(\"thinking_fast_slow_data\", exist_ok=True)\n",
    "        \n",
    "        # Determine appropriate layers based on model architecture\n",
    "        model_type = str(type(model)).lower()\n",
    "        \n",
    "        # Adjust layer indices based on model architecture\n",
    "        if \"gpt2\" in model_type:\n",
    "            # GPT-2 has 12 layers for small, 24 for medium, etc.\n",
    "            num_layers = len(model.transformer.h)\n",
    "            self.system1_layers = [int(num_layers * 0.2), int(num_layers * 0.4)]  # Earlier layers for System 1 thinking\n",
    "            self.system2_layers = [int(num_layers * 0.6), int(num_layers * 0.8)]  # Later layers for System 2 thinking\n",
    "            self.bias_layers = [int(num_layers * 0.4), int(num_layers * 0.6)]     # Middle layers for cognitive biases\n",
    "        elif \"opt\" in model_type:\n",
    "            # OPT models have varying numbers of layers\n",
    "            num_layers = len(model.model.decoder.layers)\n",
    "            self.system1_layers = [int(num_layers * 0.2), int(num_layers * 0.4)]  # Earlier layers for System 1 thinking\n",
    "            self.system2_layers = [int(num_layers * 0.6), int(num_layers * 0.8)]  # Later layers for System 2 thinking\n",
    "            self.bias_layers = [int(num_layers * 0.4), int(num_layers * 0.6)]     # Middle layers for cognitive biases\n",
    "        else:\n",
    "            # Default layer configuration for other models\n",
    "            self.system1_layers = [2, 4]  # Earlier layers for System 1 thinking\n",
    "            self.system2_layers = [6, 8]  # Later layers for System 2 thinking\n",
    "            self.bias_layers = [4, 6]     # Middle layers for cognitive biases\n",
    "            \n",
    "        print(f\"Model architecture: {model_type}\")\n",
    "        print(f\"System 1 layers: {self.system1_layers}\")\n",
    "        print(f\"System 2 layers: {self.system2_layers}\")\n",
    "        print(f\"Bias layers: {self.bias_layers}\")\n",
    "        \n",
    "        # Initialize examples for different concepts\n",
    "        self.examples = self._initialize_examples()\n",
    "    \n",
    "    def _initialize_examples(self):\n",
    "        \"\"\"\n",
    "        Initialize examples for different concepts from \"Thinking Fast and Slow\".\n",
    "        \n",
    "        Returns:\n",
    "            Dictionary mapping concept names to (positive_examples, negative_examples)\n",
    "        \"\"\"\n",
    "        examples = {}\n",
    "        \n",
    "        # System 1 vs System 2 thinking\n",
    "        examples[\"system1_thinking\"] = (\n",
    "            [\n",
    "                \"What is your immediate reaction to this image?\",\n",
    "                \"How do you feel about this situation?\",\n",
    "                \"What's your gut feeling about this person?\",\n",
    "                \"What's the first thing that comes to mind?\",\n",
    "                \"Make a quick decision about which option is better.\",\n",
    "                \"Is this person trustworthy based on their appearance?\",\n",
    "                \"Do you like this painting?\",\n",
    "                \"What's your immediate impression of this restaurant?\",\n",
    "                \"Does this feel right to you?\",\n",
    "                \"What's your instinctive response to this offer?\"\n",
    "            ],\n",
    "            [\n",
    "                \"Analyze the logical structure of this argument.\",\n",
    "                \"Calculate the expected value of this investment.\",\n",
    "                \"What are the statistical probabilities in this scenario?\",\n",
    "                \"Provide a step-by-step analysis of this problem.\",\n",
    "                \"Consider all possible outcomes before making a decision.\",\n",
    "                \"What is the mathematical formula that describes this relationship?\",\n",
    "                \"Evaluate the evidence supporting this claim.\",\n",
    "                \"What are the logical fallacies in this reasoning?\",\n",
    "                \"Calculate the compound interest over 10 years.\",\n",
    "                \"What is the most rational approach to this problem?\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        examples[\"system2_thinking\"] = (\n",
    "            examples[\"system1_thinking\"][1],  # Positive examples for System 2 are negative for System 1\n",
    "            examples[\"system1_thinking\"][0]   # Negative examples for System 2 are positive for System 1\n",
    "        )\n",
    "        \n",
    "        # Cognitive biases and heuristics\n",
    "        examples[\"priming\"] = (\n",
    "            [\n",
    "                \"After discussing food, complete the word SO_P.\",\n",
    "                \"After talking about cleanliness, complete the word SO_P.\",\n",
    "                \"After seeing elderly people, describe how quickly you walk.\",\n",
    "                \"After being asked to smile, rate how funny this joke is.\",\n",
    "                \"After reading about money, decide how to help someone.\",\n",
    "                \"After seeing images of libraries, how quietly do you speak?\",\n",
    "                \"After discussing speed, estimate how fast this car is moving.\",\n",
    "                \"After watching a sad movie, describe your current mood.\",\n",
    "                \"After reading about luxury, choose between these products.\",\n",
    "                \"After seeing examples of creativity, solve this problem.\"\n",
    "            ],\n",
    "            [\n",
    "                \"Complete the word SO_P without any context.\",\n",
    "                \"Describe how quickly you walk without any prior discussion.\",\n",
    "                \"Rate how funny this joke is objectively.\",\n",
    "                \"Decide how to help someone based solely on their needs.\",\n",
    "                \"Estimate how fast this car is moving based on physics.\",\n",
    "                \"Describe your mood based on internal reflection only.\",\n",
    "                \"Choose between these products based on their specifications.\",\n",
    "                \"Solve this problem using logical reasoning.\",\n",
    "                \"Make a decision based purely on the facts presented.\",\n",
    "                \"Evaluate this situation without any external influences.\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        examples[\"cognitive_ease\"] = (\n",
    "            [\n",
    "                \"This statement is easy to read and familiar, so it must be true.\",\n",
    "                \"I've heard this information many times, so it's probably accurate.\",\n",
    "                \"This concept is easy to understand, so it must be correct.\",\n",
    "                \"This explanation flows smoothly, so it's likely valid.\",\n",
    "                \"This idea feels familiar, so I believe it.\",\n",
    "                \"This rhyming slogan seems more accurate than the non-rhyming one.\",\n",
    "                \"This clearly printed text seems more truthful than the blurry one.\",\n",
    "                \"I've seen this brand many times, so it must be good quality.\",\n",
    "                \"This information comes from a source I like, so it's credible.\",\n",
    "                \"This concept fits with my existing beliefs, so it's probably true.\"\n",
    "            ],\n",
    "            [\n",
    "                \"Let me evaluate this statement based on evidence, not readability.\",\n",
    "                \"Frequency of exposure doesn't determine accuracy of information.\",\n",
    "                \"I should judge this concept by its logical merit, not ease of understanding.\",\n",
    "                \"The validity of an explanation isn't determined by how smoothly it flows.\",\n",
    "                \"Familiarity doesn't imply truth; I need to verify this idea.\",\n",
    "                \"Rhyming doesn't make a slogan more accurate than a non-rhyming one.\",\n",
    "                \"Print clarity doesn't affect the truthfulness of text.\",\n",
    "                \"Brand recognition doesn't guarantee quality; I need to assess objectively.\",\n",
    "                \"I should evaluate information based on evidence, not how much I like the source.\",\n",
    "                \"Compatibility with existing beliefs doesn't determine truth; I need to examine the facts.\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        examples[\"anchoring_bias\"] = (\n",
    "            [\n",
    "                \"The initial price was $1000. What do you think is a fair price?\",\n",
    "                \"The suggested donation amount is $50. How much would you like to donate?\",\n",
    "                \"The average score on this test is 85. What score do you expect to get?\",\n",
    "                \"This house was previously listed at $500,000. What would you offer?\",\n",
    "                \"The recommended daily steps are 10,000. How many steps do you think you should take?\",\n",
    "                \"The last bid was $200. What's your bid for this item?\",\n",
    "                \"Most people spend 2 hours on this task. How long do you think it will take you?\",\n",
    "                \"The speed limit here is 65 mph. How fast were you driving?\",\n",
    "                \"The standard tip is 20%. How much would you like to tip?\",\n",
    "                \"The CEO earns $5 million annually. What's a fair salary for the VP?\"\n",
    "            ],\n",
    "            [\n",
    "                \"What do you think is a fair price for this item?\",\n",
    "                \"How much would you like to donate to this cause?\",\n",
    "                \"What score do you expect to get on this test?\",\n",
    "                \"What would you offer for this house?\",\n",
    "                \"How many steps do you think you should take daily?\",\n",
    "                \"What's your bid for this item?\",\n",
    "                \"How long do you think this task will take you?\",\n",
    "                \"How fast were you driving?\",\n",
    "                \"How much would you like to tip?\",\n",
    "                \"What's a fair salary for the VP?\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        examples[\"framing_effect\"] = (\n",
    "            [\n",
    "                \"The treatment has a 70% success rate. Would you recommend it?\",\n",
    "                \"This investment has a 60% chance of making a profit. Is it worth it?\",\n",
    "                \"The program will save 200 out of 600 lives. Do you support it?\",\n",
    "                \"This policy will create jobs for 5% of the unemployed. Should we implement it?\",\n",
    "                \"The product has satisfied 90% of customers. Would you buy it?\",\n",
    "                \"This surgery has an 80% survival rate. Would you undergo it?\",\n",
    "                \"This diet plan helps 70% of people lose weight. Would you try it?\",\n",
    "                \"This security system prevents 75% of break-ins. Is it effective?\",\n",
    "                \"This vaccine protects 95% of recipients. Would you get vaccinated?\",\n",
    "                \"This educational program improves test scores for 65% of students. Is it valuable?\"\n",
    "            ],\n",
    "            [\n",
    "                \"The treatment has a 30% failure rate. Would you recommend it?\",\n",
    "                \"This investment has a 40% chance of losing money. Is it worth it?\",\n",
    "                \"The program will allow 400 out of 600 people to die. Do you support it?\",\n",
    "                \"This policy will leave 95% of the unemployed without jobs. Should we implement it?\",\n",
    "                \"The product has dissatisfied 10% of customers. Would you buy it?\",\n",
    "                \"This surgery has a 20% mortality rate. Would you undergo it?\",\n",
    "                \"This diet plan fails to help 30% of people lose weight. Would you try it?\",\n",
    "                \"This security system fails to prevent 25% of break-ins. Is it effective?\",\n",
    "                \"This vaccine leaves 5% of recipients unprotected. Would you get vaccinated?\",\n",
    "                \"This educational program doesn't improve test scores for 35% of students. Is it valuable?\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        examples[\"availability_bias\"] = (\n",
    "            [\n",
    "                \"After hearing about a plane crash, how safe do you feel flying?\",\n",
    "                \"After reading about shark attacks, how dangerous do you think swimming in the ocean is?\",\n",
    "                \"After seeing news about lottery winners, how likely do you think winning the lottery is?\",\n",
    "                \"After hearing about a terrorist attack, how concerned are you about terrorism?\",\n",
    "                \"After reading about a rare disease, how worried are you about contracting it?\",\n",
    "                \"After watching a documentary about serial killers, how safe do you feel walking alone?\",\n",
    "                \"After hearing about a friend's divorce, how stable do you think marriages are?\",\n",
    "                \"After reading about a stock market crash, how risky do you think investing is?\",\n",
    "                \"After seeing news about car accidents, how dangerous do you think driving is?\",\n",
    "                \"After hearing about a home invasion, how concerned are you about your home security?\"\n",
    "            ],\n",
    "            [\n",
    "                \"Based on statistics, how safe is flying compared to other forms of transportation?\",\n",
    "                \"Statistically, how dangerous is swimming in the ocean?\",\n",
    "                \"What are the actual odds of winning the lottery?\",\n",
    "                \"Based on data, how likely are you to be affected by terrorism?\",\n",
    "                \"What is the statistical prevalence of this disease in the population?\",\n",
    "                \"What is the statistical likelihood of being a victim of violent crime?\",\n",
    "                \"What percentage of marriages end in divorce according to recent statistics?\",\n",
    "                \"What is the historical long-term performance of the stock market?\",\n",
    "                \"What is the statistical risk of being in a car accident per mile driven?\",\n",
    "                \"What is the actual rate of home invasions in your neighborhood?\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        examples[\"loss_aversion\"] = (\n",
    "            [\n",
    "                \"Would you accept a bet with a 50% chance to lose $100 and a 50% chance to win $150?\",\n",
    "                \"Would you sell this item that has sentimental value for twice what you paid for it?\",\n",
    "                \"Would you risk losing your current job for a 60% chance at a better one?\",\n",
    "                \"Would you give up your current phone for a 70% chance at a better model?\",\n",
    "                \"Would you trade your current car plus cash for a newer model?\",\n",
    "                \"Would you sell your concert tickets for 50% more than you paid?\",\n",
    "                \"Would you risk your $1000 investment for a 60% chance to earn $2000?\",\n",
    "                \"Would you give up your vacation plans for a refund plus 20%?\",\n",
    "                \"Would you exchange your current laptop for a different model?\",\n",
    "                \"Would you cancel your subscription for a 40% refund?\"\n",
    "            ],\n",
    "            [\n",
    "                \"Would you accept a bet with a 50% chance to win $150 and a 50% chance to lose $100?\",\n",
    "                \"Would you buy this item with sentimental value for twice its market price?\",\n",
    "                \"Would you take a new job with a 60% chance of being better than your current one?\",\n",
    "                \"Would you buy a new phone with a 70% chance of being better than your current one?\",\n",
    "                \"Would you pay cash plus your current car for a newer model?\",\n",
    "                \"Would you buy concert tickets for 50% more than their face value?\",\n",
    "                \"Would you invest $1000 for a 60% chance to earn $2000?\",\n",
    "                \"Would you pay 20% extra to maintain your vacation plans?\",\n",
    "                \"Would you buy a different laptop model to replace your current one?\",\n",
    "                \"Would you pay 40% more to continue your subscription?\"\n",
    "            ]\n",
    "        )\n",
    "        \n",
    "        return examples\n",
    "    \n",
    "    def train_concept(self, concept_name, num_examples=3):\n",
    "        \"\"\"\n",
    "        Train a CAV for a specific concept from \"Thinking Fast and Slow\".\n",
    "        \n",
    "        Args:\n",
    "            concept_name: Name of the concept to train\n",
    "            num_examples: Number of examples to use for training\n",
    "            \n",
    "        Returns:\n",
    "            Trained concept vectors\n",
    "        \"\"\"\n",
    "        if concept_name not in self.examples:\n",
    "            raise ValueError(f\"Unknown concept: {concept_name}. Available concepts: {list(self.examples.keys())}\")\n",
    "        \n",
    "        positive_examples, negative_examples = self.examples[concept_name]\n",
    "        \n",
    "        # Use appropriate layers based on the concept\n",
    "        if concept_name == \"system1_thinking\":\n",
    "            layers = self.system1_layers\n",
    "        elif concept_name == \"system2_thinking\":\n",
    "            layers = self.system2_layers\n",
    "        else:\n",
    "            layers = self.bias_layers\n",
    "        \n",
    "        # Ensure we have enough examples\n",
    "        if len(positive_examples) < num_examples or len(negative_examples) < num_examples:\n",
    "            print(f\"Warning: Not enough examples for {concept_name}. Using all available examples.\")\n",
    "            num_examples = min(len(positive_examples), len(negative_examples))\n",
    "        \n",
    "        # Select random subset if we have more examples than needed\n",
    "        if len(positive_examples) > num_examples:\n",
    "            positive_subset = random.sample(positive_examples, num_examples)\n",
    "        else:\n",
    "            positive_subset = positive_examples\n",
    "            \n",
    "        if len(negative_examples) > num_examples:\n",
    "            negative_subset = random.sample(negative_examples, num_examples)\n",
    "        else:\n",
    "            negative_subset = negative_examples\n",
    "        \n",
    "        # Train the concept vector\n",
    "        return self.cav.train_concept_vector(concept_name, positive_subset, negative_subset, layers)\n",
    "    \n",
    "    def train_all_concepts(self, num_examples=3):\n",
    "        \"\"\"\n",
    "        Train CAVs for all concepts from \"Thinking Fast and Slow\".\n",
    "        \n",
    "        Args:\n",
    "            num_examples: Number of examples to use for each concept\n",
    "        \"\"\"\n",
    "        for concept in self.examples.keys():\n",
    "            print(f\"\\nTraining concept: {concept}\")\n",
    "            self.train_concept(concept, num_examples)\n",
    "    \n",
    "    def apply_system_thinking(self, prompt, system=1, steering_strength=1.0, max_tokens=100):\n",
    "        \"\"\"\n",
    "        Apply System 1 or System 2 thinking to generation.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Input prompt\n",
    "            system: Which system to apply (1 or 2)\n",
    "            steering_strength: Strength of steering\n",
    "            max_tokens: Maximum number of tokens to generate\n",
    "            \n",
    "        Returns:\n",
    "            Generated text with System 1 or 2 thinking applied\n",
    "        \"\"\"\n",
    "        if system == 1:\n",
    "            concept = \"system1_thinking\"\n",
    "            layers = self.system1_layers\n",
    "        elif system == 2:\n",
    "            concept = \"system2_thinking\"\n",
    "            layers = self.system2_layers\n",
    "        else:\n",
    "            raise ValueError(\"System must be 1 or 2\")\n",
    "        \n",
    "        return self.cav.apply_steering(prompt, concept, layers, steering_strength, max_tokens)\n",
    "    \n",
    "    def apply_cognitive_bias(self, prompt, bias, steering_strength=1.0, max_tokens=100):\n",
    "        \"\"\"\n",
    "        Apply a specific cognitive bias to generation.\n",
    "        \n",
    "        Args:\n",
    "            prompt: Input prompt\n",
    "            bias: Which bias to apply (e.g., \"anchoring_bias\", \"framing_effect\")\n",
    "            steering_strength: Strength of steering\n",
    "            max_tokens: Maximum number of tokens to generate\n",
    "            \n",
    "        Returns:\n",
    "            Generated text with the specified bias applied\n",
    "        \"\"\"\n",
    "        if bias not in self.examples:\n",
    "            raise ValueError(f\"Unknown bias: {bias}. Available biases: {list(self.examples.keys())}\")\n",
    "        \n",
    "        return self.cav.apply_steering(prompt, bias, self.bias_layers, steering_strength, max_tokens)\n",
    "    \n",
    "    def save_concepts(self, filepath=\"thinking_fast_slow_concepts.json\"):\n",
    "        \"\"\"Save all trained concept vectors.\"\"\"\n",
    "        self.cav.save_concept_vectors(filepath)\n",
    "    \n",
    "    def load_concepts(self, filepath=\"thinking_fast_slow_concepts.json\"):\n",
    "        \"\"\"Load all trained concept vectors.\"\"\"\n",
    "        if not os.path.exists(filepath):\n",
    "            print(f\"No saved concepts found at {filepath}. Train concepts first.\")\n",
    "            return False\n",
    "        \n",
    "        self.cav.load_concept_vectors(filepath)\n",
    "        return True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Initialize and Train CAVs\n",
    "\n",
    "Now, let's initialize our Thinking Fast and Slow CAV implementation and train the concept vectors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model architecture: <class 'transformers.models.opt.modeling_opt.optforcausallm'>\n",
      "System 1 layers: [4, 9]\n",
      "System 2 layers: [14, 19]\n",
      "Bias layers: [9, 14]\n"
     ]
    }
   ],
   "source": [
    "# Initialize the implementation\n",
    "tfs_cav = ThinkingFastSlowCAV(model, tokenizer, device=\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training concept vector for 'system1_thinking'...\n",
      "Removed all hooks\n",
      "Registered hook for layer 4\n",
      "Registered hook for layer 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2f6dba1a1e884e00961e1afbb4ab8a3f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting activations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed all hooks\n",
      "Removed all hooks\n",
      "Registered hook for layer 4\n",
      "Registered hook for layer 9\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4ad3f4557eaa401883db677224aacc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting activations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed all hooks\n",
      "Layer 4 activation shapes:\n",
      "  Positive example 0: torch.Size([1, 9, 2048])\n",
      "  Positive example 1: torch.Size([1, 10, 2048])\n",
      "  Negative example 0: torch.Size([1, 10, 2048])\n",
      "  Negative example 1: torch.Size([1, 14, 2048])\n",
      "After pooling - X_positive shape: (2, 2048), X_negative shape: (2, 2048)\n",
      "  Layer 4: Classifier accuracy = 1.0000\n",
      "Layer 9 activation shapes:\n",
      "  Positive example 0: torch.Size([1, 9, 2048])\n",
      "  Positive example 1: torch.Size([1, 10, 2048])\n",
      "  Negative example 0: torch.Size([1, 10, 2048])\n",
      "  Negative example 1: torch.Size([1, 14, 2048])\n",
      "After pooling - X_positive shape: (2, 2048), X_negative shape: (2, 2048)\n",
      "  Layer 9: Classifier accuracy = 1.0000\n",
      "Training concept vector for 'system2_thinking'...\n",
      "Removed all hooks\n",
      "Registered hook for layer 14\n",
      "Registered hook for layer 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ada5751c48cd4c629e45ec698bd4968e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting activations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed all hooks\n",
      "Removed all hooks\n",
      "Registered hook for layer 14\n",
      "Registered hook for layer 19\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "471b3cf50aee4f8a801df6e04acc7137",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting activations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed all hooks\n",
      "Layer 14 activation shapes:\n",
      "  Positive example 0: torch.Size([1, 14, 2048])\n",
      "  Positive example 1: torch.Size([1, 10, 2048])\n",
      "  Negative example 0: torch.Size([1, 9, 2048])\n",
      "  Negative example 1: torch.Size([1, 8, 2048])\n",
      "After pooling - X_positive shape: (2, 2048), X_negative shape: (2, 2048)\n",
      "  Layer 14: Classifier accuracy = 1.0000\n",
      "Layer 19 activation shapes:\n",
      "  Positive example 0: torch.Size([1, 14, 2048])\n",
      "  Positive example 1: torch.Size([1, 10, 2048])\n",
      "  Negative example 0: torch.Size([1, 9, 2048])\n",
      "  Negative example 1: torch.Size([1, 8, 2048])\n",
      "After pooling - X_positive shape: (2, 2048), X_negative shape: (2, 2048)\n",
      "  Layer 19: Classifier accuracy = 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{14: tensor([-0.0044,  0.0063, -0.0187,  ..., -0.0132, -0.0106,  0.0391]),\n",
       " 19: tensor([ 0.0129,  0.0199, -0.0125,  ..., -0.0011, -0.0306,  0.0266])}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train System 1 and System 2 thinking CAVs\n",
    "# Start with a smaller number of examples for testing\n",
    "tfs_cav.train_concept(\"system1_thinking\", num_examples=2)\n",
    "tfs_cav.train_concept(\"system2_thinking\", num_examples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training concept vector for 'anchoring_bias'...\n",
      "Removed all hooks\n",
      "Registered hook for layer 9\n",
      "Registered hook for layer 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6dd4e9fcdffd4169bae7d41e7bb163b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting activations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed all hooks\n",
      "Removed all hooks\n",
      "Registered hook for layer 9\n",
      "Registered hook for layer 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37f4731ab8ed4d568b5499cd77ed0c92",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting activations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed all hooks\n",
      "Layer 9 activation shapes:\n",
      "  Positive example 0: torch.Size([1, 17, 2048])\n",
      "  Positive example 1: torch.Size([1, 20, 2048])\n",
      "  Negative example 0: torch.Size([1, 13, 2048])\n",
      "  Negative example 1: torch.Size([1, 10, 2048])\n",
      "After pooling - X_positive shape: (2, 2048), X_negative shape: (2, 2048)\n",
      "  Layer 9: Classifier accuracy = 1.0000\n",
      "Layer 14 activation shapes:\n",
      "  Positive example 0: torch.Size([1, 17, 2048])\n",
      "  Positive example 1: torch.Size([1, 20, 2048])\n",
      "  Negative example 0: torch.Size([1, 13, 2048])\n",
      "  Negative example 1: torch.Size([1, 10, 2048])\n",
      "After pooling - X_positive shape: (2, 2048), X_negative shape: (2, 2048)\n",
      "  Layer 14: Classifier accuracy = 1.0000\n",
      "Training concept vector for 'framing_effect'...\n",
      "Removed all hooks\n",
      "Registered hook for layer 9\n",
      "Registered hook for layer 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc983d9d5464dcd8e69756df6d9565f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting activations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed all hooks\n",
      "Removed all hooks\n",
      "Registered hook for layer 9\n",
      "Registered hook for layer 14\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7c44762e06b47e49726f8aca58db4f3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Collecting activations:   0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Removed all hooks\n",
      "Layer 9 activation shapes:\n",
      "  Positive example 0: torch.Size([1, 18, 2048])\n",
      "  Positive example 1: torch.Size([1, 18, 2048])\n",
      "  Negative example 0: torch.Size([1, 18, 2048])\n",
      "  Negative example 1: torch.Size([1, 15, 2048])\n",
      "After pooling - X_positive shape: (2, 2048), X_negative shape: (2, 2048)\n",
      "  Layer 9: Classifier accuracy = 1.0000\n",
      "Layer 14 activation shapes:\n",
      "  Positive example 0: torch.Size([1, 18, 2048])\n",
      "  Positive example 1: torch.Size([1, 18, 2048])\n",
      "  Negative example 0: torch.Size([1, 18, 2048])\n",
      "  Negative example 1: torch.Size([1, 15, 2048])\n",
      "After pooling - X_positive shape: (2, 2048), X_negative shape: (2, 2048)\n",
      "  Layer 14: Classifier accuracy = 1.0000\n"
     ]
    }
   ],
   "source": [
    "# Train cognitive bias CAVs\n",
    "# Note: Training all biases can take time, so we'll just train a few for demonstration\n",
    "biases_to_train = [\"anchoring_bias\", \"framing_effect\"]\n",
    "\n",
    "for bias in biases_to_train:\n",
    "    tfs_cav.train_concept(bias, num_examples=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Concept vectors saved to thinking_fast_slow_concepts.json\n"
     ]
    }
   ],
   "source": [
    "# Save the trained concept vectors\n",
    "tfs_cav.save_concepts(\"thinking_fast_slow_concepts.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Test System 1 vs System 2 Thinking\n",
    "\n",
    "Let's test how our CAVs can steer the model to exhibit System 1 (fast, intuitive) or System 2 (slow, deliberate) thinking patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Should I invest in this new technology company?\n",
      "\n",
      "System 1 (Fast, Intuitive) Thinking:\n",
      "Registered steering hook for layer 4\n",
      "Registered steering hook for layer 9\n",
      "Should I invest in this new technology company?\n",
      "The share price of Zoopla (LSE: ZOOP) has fallen by more than a fifth since the company reported its financial results for the first half of the year.\n",
      "This is a big fall for the company and its investors, as it was trading at a price-to-earnings ratio of around 21.\n",
      "This is not a cheap price, but it is a price that is lower than the valuation of the company itself.\n",
      "The companys financial performance\n",
      "\n",
      "System 2 (Slow, Deliberate) Thinking:\n",
      "Registered steering hook for layer 14\n",
      "Registered steering hook for layer 19\n",
      "Should I invest in this new technology company?\n",
      "\n",
      "The following article was written by Chris D. on behalf of Dividend Growth Investor.\n",
      "\n",
      "Introduction\n",
      "\n",
      "The company is developing a new technology called the \"P2P Trading Platform\". This platform will allow investors to trade on the P2P market without having to deal with brokers and with minimal risk.\n",
      "\n",
      "The company has been successful in securing funding and has raised over $100 million. The company has already raised over $100 million in funding, and they are expecting to\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Prompt: Is this a good time to buy a house?\n",
      "\n",
      "System 1 (Fast, Intuitive) Thinking:\n",
      "Registered steering hook for layer 4\n",
      "Registered steering hook for layer 9\n",
      "Is this a good time to buy a house?\n",
      "\n",
      "In the last few months, we have been seeing a lot of signs of interest in the market. Its not uncommon to see a buyers agent say, We have seen a lot of interest in the market.\n",
      "\n",
      "There are a lot of reasons for this.\n",
      "\n",
      "The economy is improving. The unemployment rate is at an all-time low. The housing market is in the best shape it has been in years.\n",
      "\n",
      "With that\n",
      "\n",
      "System 2 (Slow, Deliberate) Thinking:\n",
      "Registered steering hook for layer 14\n",
      "Registered steering hook for layer 19\n",
      "Is this a good time to buy a house?\n",
      "\n",
      "Im a college graduate with a great job in my field of study. I have a good savings account, Ive got a little bit of cash in a CD, and Im in the process of building up my emergency fund. Im making good progress, but Im not completely out of the woods.\n",
      "\n",
      "Im wondering if now is a good time to buy a house? Im not looking to\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test prompts for System 1 vs System 2 thinking\n",
    "test_prompts = [\n",
    "    \"Should I invest in this new technology company?\",\n",
    "    \"Is this a good time to buy a house?\"\n",
    "]\n",
    "\n",
    "# Test System 1 vs System 2 thinking\n",
    "for prompt in test_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    \n",
    "    print(\"\\nSystem 1 (Fast, Intuitive) Thinking:\")\n",
    "    system1_response = tfs_cav.apply_system_thinking(prompt, system=1, steering_strength=1.5)\n",
    "    print(system1_response)\n",
    "    \n",
    "    print(\"\\nSystem 2 (Slow, Deliberate) Thinking:\")\n",
    "    system2_response = tfs_cav.apply_system_thinking(prompt, system=2, steering_strength=1.5)\n",
    "    print(system2_response)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Test Cognitive Biases\n",
    "\n",
    "Now, let's test how our CAVs can induce specific cognitive biases from \"Thinking Fast and Slow\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: What do you think is a fair price for this laptop?\n",
      "\n",
      "Without anchoring bias:\n",
      "Registered steering hook for layer 9\n",
      "Registered steering hook for layer 14\n",
      "What do you think is a fair price for this laptop?\n",
      "I'd be happy to take $200 if you want to send me a list. I'm in a similar situation. I have a couple of friends who would be interested in the same thing.\n",
      "\n",
      "With anchoring bias:\n",
      "Registered steering hook for layer 9\n",
      "Registered steering hook for layer 14\n",
      "The typical amount is $1,500. What do you think is a fair price for this laptop?\n",
      "I'm not sure I understand what you're asking. Are you asking me what the typical price of a MacBook Air is, or what I would be asking for this laptop?\n",
      "The typical price of a MacBook Air is $1,500. What do you think is a fair price for this laptop?\n",
      "I'm not sure I understand what you're asking. Are you asking me what the typical price of a MacBook Air is, or what I would be asking for this laptop?\n",
      "What\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test anchoring bias\n",
    "anchoring_prompts = [\n",
    "    \"What do you think is a fair price for this laptop?\"\n",
    "]\n",
    "\n",
    "for prompt in anchoring_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    \n",
    "    print(\"\\nWithout anchoring bias:\")\n",
    "    no_bias_response = tfs_cav.cav.apply_steering(prompt, \"anchoring_bias\", tfs_cav.bias_layers, 0.0)\n",
    "    print(no_bias_response)\n",
    "    \n",
    "    print(\"\\nWith anchoring bias:\")\n",
    "    anchored_prompt = f\"The typical amount is $1,500. {prompt}\"\n",
    "    bias_response = tfs_cav.apply_cognitive_bias(anchored_prompt, \"anchoring_bias\", steering_strength=1.5)\n",
    "    print(bias_response)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Prompt: Would you recommend this medical treatment?\n",
      "\n",
      "Positive framing:\n",
      "Registered steering hook for layer 9\n",
      "Registered steering hook for layer 14\n",
      "This has a 70% success rate. Would you recommend this medical treatment?\n",
      "I would recommend this medical treatment if I was a doctor.\n",
      "You are a doctor. You are a doctor.   *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/oldpeoplefacebook) if you have any questions or concerns.*\n",
      "\n",
      "Negative framing:\n",
      "Registered steering hook for layer 9\n",
      "Registered steering hook for layer 14\n",
      "This has a 30% failure rate. Would you recommend this medical treatment?\n",
      "I'm not sure I can say it's 100% effective, but I can say that I've never had a problem.   I'd say yes, if you can afford it, because it's pretty much the only way to get rid of it.\n",
      "\n",
      "--------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Test framing effect\n",
    "framing_prompts = [\n",
    "    \"Would you recommend this medical treatment?\"\n",
    "]\n",
    "\n",
    "for prompt in framing_prompts:\n",
    "    print(f\"\\nPrompt: {prompt}\")\n",
    "    \n",
    "    print(\"\\nPositive framing:\")\n",
    "    positive_prompt = f\"This has a 70% success rate. {prompt}\"\n",
    "    positive_response = tfs_cav.apply_cognitive_bias(positive_prompt, \"framing_effect\", steering_strength=1.5)\n",
    "    print(positive_response)\n",
    "    \n",
    "    print(\"\\nNegative framing:\")\n",
    "    negative_prompt = f\"This has a 30% failure rate. {prompt}\"\n",
    "    negative_response = tfs_cav.apply_cognitive_bias(negative_prompt, \"framing_effect\", steering_strength=-1.5)\n",
    "    print(negative_response)\n",
    "    \n",
    "    print(\"\\n\" + \"-\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Create a Test Set\n",
    "\n",
    "Let's create a comprehensive test set based on \"Thinking Fast and Slow\" that you can use to evaluate the CAV implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set created and saved to 'thinking_fast_slow_test_set.json'\n"
     ]
    }
   ],
   "source": [
    "def create_test_set():\n",
    "    \"\"\"\n",
    "    Create a comprehensive test set based on \"Thinking Fast and Slow\".\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary containing test prompts for different concepts\n",
    "    \"\"\"\n",
    "    test_set = {}\n",
    "    \n",
    "    # System 1 vs System 2 thinking\n",
    "    test_set[\"system_thinking\"] = [\n",
    "        \"What career path should I choose?\",\n",
    "        \"Should I buy or rent a home?\",\n",
    "        \"Is this a good investment opportunity?\",\n",
    "        \"Should I trust this person?\",\n",
    "        \"Is this product worth the price?\",\n",
    "        \"Should I take this medication?\",\n",
    "        \"Is this the right time to start a business?\",\n",
    "        \"Should I accept this job offer?\",\n",
    "        \"Is this a good time to have children?\",\n",
    "        \"Should I pursue higher education?\"\n",
    "    ]\n",
    "    \n",
    "    # Cognitive biases\n",
    "    test_set[\"anchoring_bias\"] = [\n",
    "        (\"What's a reasonable price for this smartphone?\", \"The last model was priced at $999. What's a reasonable price for this smartphone?\"),\n",
    "        (\"How much should I tip for this meal?\", \"The suggested tip is 20%. How much should I tip for this meal?\"),\n",
    "        (\"How many pages should I read daily?\", \"Most people read 50 pages daily. How many pages should I read daily?\"),\n",
    "        (\"What's a good salary for this position?\", \"The industry average is $85,000. What's a good salary for this position?\"),\n",
    "        (\"How much should I save for retirement each month?\", \"Financial advisors recommend saving 15% of income. How much should I save for retirement each month?\")\n",
    "    ]\n",
    "    \n",
    "    test_set[\"framing_effect\"] = [\n",
    "        (\"This treatment has a 70% success rate. Would you recommend it?\", \"This treatment has a 30% failure rate. Would you recommend it?\"),\n",
    "        (\"This policy will save 200 jobs. Do you support it?\", \"This policy will lose 800 jobs. Do you support it?\"),\n",
    "        (\"This investment has a 60% chance of profit. Is it worth it?\", \"This investment has a 40% chance of loss. Is it worth it?\"),\n",
    "        (\"This program will help 30% of students improve their grades. Is it effective?\", \"This program will fail to help 70% of students improve their grades. Is it effective?\"),\n",
    "        (\"This security system prevents 80% of break-ins. Should you install it?\", \"This security system fails to prevent 20% of break-ins. Should you install it?\")\n",
    "    ]\n",
    "    \n",
    "    test_set[\"availability_bias\"] = [\n",
    "        (\"How safe is flying?\", \"After hearing about a recent plane crash, how safe is flying?\"),\n",
    "        (\"How dangerous are sharks?\", \"After watching a documentary about shark attacks, how dangerous are sharks?\"),\n",
    "        (\"What are the chances of being a victim of crime?\", \"After reading news about a local crime, what are the chances of being a victim of crime?\"),\n",
    "        (\"How risky is the stock market?\", \"After hearing about a market crash, how risky is the stock market?\"),\n",
    "        (\"How common are terrorist attacks?\", \"After seeing coverage of a terrorist attack, how common are terrorist attacks?\")\n",
    "    ]\n",
    "    \n",
    "    test_set[\"loss_aversion\"] = [\n",
    "        (\"Would you accept a bet with a 50% chance to win $150 and a 50% chance to lose $100?\", \"Would you accept a bet with a 50% chance to lose $100 and a 50% chance to win $150?\"),\n",
    "        (\"Would you switch to a new job with a 60% chance of higher satisfaction?\", \"Would you leave your current job with a 40% chance of lower satisfaction?\"),\n",
    "        (\"Would you invest in a stock with a 70% chance of gaining value?\", \"Would you invest in a stock with a 30% chance of losing value?\"),\n",
    "        (\"Would you try a new medication with a 80% chance of improvement?\", \"Would you try a new medication with a 20% chance of side effects?\"),\n",
    "        (\"Would you upgrade to a new phone with better features?\", \"Would you give up your current phone for a different model?\")\n",
    "    ]\n",
    "    \n",
    "    test_set[\"priming\"] = [\n",
    "        (\"Complete the word SO_P.\", \"After discussing food, complete the word SO_P.\"),\n",
    "        (\"How fast would you walk down this hallway?\", \"After seeing pictures of elderly people, how fast would you walk down this hallway?\"),\n",
    "        (\"Rate how funny this joke is on a scale of 1-10.\", \"After being asked to smile, rate how funny this joke is on a scale of 1-10.\"),\n",
    "        (\"How would you describe your current mood?\", \"After watching a happy video clip, how would you describe your current mood?\"),\n",
    "        (\"How much would you be willing to pay for this product?\", \"After seeing luxury items, how much would you be willing to pay for this product?\")\n",
    "    ]\n",
    "    \n",
    "    test_set[\"cognitive_ease\"] = [\n",
    "        (\"Evaluate whether this statement is true: 'Exercise improves health.'\", \"This statement is easy to read and familiar: 'Exercise improves health.' Is it true?\"),\n",
    "        (\"Is this information accurate: 'Drinking water is essential.'\", \"You've heard this many times before: 'Drinking water is essential.' Is it accurate?\"),\n",
    "        (\"Assess this claim: 'Technology enhances productivity.'\", \"This concept is easy to understand: 'Technology enhances productivity.' Assess this claim.\"),\n",
    "        (\"Is this valid: 'Early birds catch more worms.'\", \"This rhyming phrase sounds right: 'Early birds catch more worms.' Is it valid?\"),\n",
    "        (\"Evaluate this brand's quality.\", \"You've seen this brand advertised frequently. Evaluate its quality.\")\n",
    "    ]\n",
    "    \n",
    "    return test_set\n",
    "\n",
    "# Create and save the test set\n",
    "test_set = create_test_set()\n",
    "\n",
    "with open(\"thinking_fast_slow_test_set.json\", \"w\") as f:\n",
    "    json.dump(test_set, f, indent=2)\n",
    "\n",
    "print(\"Test set created and saved to 'thinking_fast_slow_test_set.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. Evaluation Function\n",
    "\n",
    "Let's create a function to evaluate the effectiveness of our CAVs using the test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating anchoring_bias...\n",
      "Registered steering hook for layer 9\n",
      "Registered steering hook for layer 14\n",
      "Registered steering hook for layer 9\n",
      "Registered steering hook for layer 14\n",
      "Evaluation results saved to 'cav_evaluation_results.json'\n"
     ]
    }
   ],
   "source": [
    "def evaluate_cav_effectiveness(tfs_cav, test_set, bias_to_evaluate=None):\n",
    "    \"\"\"\n",
    "    Evaluate the effectiveness of CAVs using the test set.\n",
    "    \n",
    "    Args:\n",
    "        tfs_cav: ThinkingFastSlowCAV instance\n",
    "        test_set: Dictionary containing test prompts\n",
    "        bias_to_evaluate: Specific bias to evaluate (if None, evaluate all)\n",
    "        \n",
    "    Returns:\n",
    "        Dictionary containing evaluation results\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    # Evaluate System 1 vs System 2 thinking\n",
    "    if bias_to_evaluate is None or bias_to_evaluate == \"system_thinking\":\n",
    "        print(\"Evaluating System 1 vs System 2 thinking...\")\n",
    "        system_results = []\n",
    "        \n",
    "        for prompt in test_set[\"system_thinking\"][:1]:  # Limit to 1 for demonstration\n",
    "            try:\n",
    "                system1_response = tfs_cav.apply_system_thinking(prompt, system=1, steering_strength=1.5)\n",
    "                system2_response = tfs_cav.apply_system_thinking(prompt, system=2, steering_strength=1.5)\n",
    "                \n",
    "                system_results.append({\n",
    "                    \"prompt\": prompt,\n",
    "                    \"system1_response\": system1_response,\n",
    "                    \"system2_response\": system2_response\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating system thinking for prompt '{prompt}': {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        results[\"system_thinking\"] = system_results\n",
    "    \n",
    "    # Evaluate cognitive biases\n",
    "    biases = [\"anchoring_bias\", \"framing_effect\"]\n",
    "    \n",
    "    for bias in biases:\n",
    "        if bias_to_evaluate is not None and bias != bias_to_evaluate:\n",
    "            continue\n",
    "            \n",
    "        if bias not in test_set:\n",
    "            continue\n",
    "            \n",
    "        print(f\"Evaluating {bias}...\")\n",
    "        bias_results = []\n",
    "        \n",
    "        for prompt_pair in test_set[bias][:1]:  # Limit to 1 for demonstration\n",
    "            control_prompt, biased_prompt = prompt_pair\n",
    "            \n",
    "            try:\n",
    "                # Generate responses\n",
    "                control_response = tfs_cav.cav.apply_steering(control_prompt, bias, tfs_cav.bias_layers, 0.0)\n",
    "                biased_response = tfs_cav.apply_cognitive_bias(biased_prompt, bias, steering_strength=1.5)\n",
    "                \n",
    "                bias_results.append({\n",
    "                    \"control_prompt\": control_prompt,\n",
    "                    \"biased_prompt\": biased_prompt,\n",
    "                    \"control_response\": control_response,\n",
    "                    \"biased_response\": biased_response\n",
    "                })\n",
    "            except Exception as e:\n",
    "                print(f\"Error evaluating {bias} for prompt '{control_prompt}': {e}\")\n",
    "                import traceback\n",
    "                traceback.print_exc()\n",
    "        \n",
    "        results[bias] = bias_results\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Note: Uncomment to run evaluation (this can take time)\n",
    "evaluation_results = evaluate_cav_effectiveness(tfs_cav, test_set, bias_to_evaluate=\"anchoring_bias\")\n",
    "\n",
    "with open(\"cav_evaluation_results.json\", \"w\") as f:\n",
    "     json.dump(evaluation_results, f, indent=2)\n",
    " \n",
    "print(\"Evaluation results saved to 'cav_evaluation_results.json'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. Conclusion and Next Steps\n",
    "\n",
    "In this notebook, we've implemented Concept Activation Vectors (CAVs) to replicate cognitive theories from Daniel Kahneman's \"Thinking Fast and Slow\". We've demonstrated how to:\n",
    "\n",
    "1. Create a CAV implementation for manipulating model behavior\n",
    "2. Train CAVs for System 1 and System 2 thinking patterns\n",
    "3. Train CAVs for specific cognitive biases from the book\n",
    "4. Test the CAVs on examples from \"Thinking Fast and Slow\"\n",
    "5. Create a comprehensive test set for evaluation\n",
    "\n",
    "### Apple Silicon Compatibility Notes\n",
    "\n",
    "This notebook has been specifically optimized for Apple Silicon (M1/M2/M3) Macs by:\n",
    "- Completely disabling MPS device usage to avoid compatibility issues\n",
    "- Using mean pooling for activation processing to avoid dimension mismatch errors\n",
    "- Adding explicit device management for tensors\n",
    "- Including comprehensive error handling and debugging information\n",
    "- Reducing the number of examples for faster testing\n",
    "- Adding dimension compatibility checks in the steering hooks\n",
    "\n",
    "### Next Steps\n",
    "\n",
    "To further extend this work, you could:\n",
    "\n",
    "1. Train CAVs for additional cognitive biases from the book\n",
    "2. Experiment with different layer selections for different biases\n",
    "3. Develop more sophisticated evaluation metrics\n",
    "4. Combine multiple biases to create more complex cognitive patterns\n",
    "5. Compare CAV-based steering with other approaches like fine-tuning\n",
    "\n",
    "This implementation provides a foundation for using CAVs to replicate and study cognitive biases in language models, offering insights into both human cognition and AI behavior."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "fine-tune",
   "language": "python",
   "name": "fine-tune"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
