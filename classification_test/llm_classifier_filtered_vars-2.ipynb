{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "68fc7d53",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import torch\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.optim import AdamW\n",
    "from transformers import RobertaTokenizer, RobertaForSequenceClassification, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "from sklearn.metrics import classification_report, confusion_matrix, roc_auc_score\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1ad508db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a327a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_legitimate_features(responses):\n",
    "    \"\"\"\n",
    "    Extract only legitimate, non-leaky features from the responses.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Helper to extract response safely\n",
    "    def extract_response(responses, code):\n",
    "        for r in responses:\n",
    "            if r[\"variable_code\"] == code:\n",
    "                ans = r.get(\"respondent_answer\")\n",
    "                if ans in ['Inapplicable', 'Refused', \"Don't know\", 'Error']:\n",
    "                    return \"NA\"\n",
    "                return str(ans)\n",
    "        return \"NA\"\n",
    "    \n",
    "    # Demographic features\n",
    "    features[\"political_interest\"] = extract_response(responses, \"V241004\")  # Political interest\n",
    "    features[\"campaign_interest\"] = extract_response(responses, \"V241005\")   # Campaign interest\n",
    "    \n",
    "    # Economic views (if available)\n",
    "    features[\"economic_views\"] = extract_response(responses, \"V241127\")\n",
    "    \n",
    "    # State/region information\n",
    "    features[\"state\"] = extract_response(responses, \"V241017\")\n",
    "    \n",
    "    # Media consumption (example)\n",
    "    features[\"media_consumption\"] = extract_response(responses, \"V241201\")\n",
    "    \n",
    "    # Convert features to a single text representation\n",
    "    input_text = (\n",
    "        f\"Political interest: {features['political_interest']}\\n\"\n",
    "        f\"Campaign interest: {features['campaign_interest']}\\n\"\n",
    "        f\"Economic views: {features['economic_views']}\\n\"\n",
    "        f\"State: {features['state']}\\n\"\n",
    "        f\"Media consumption: {features['media_consumption']}\\n\"\n",
    "        f\"Q: Who would this respondent vote for in a Harris vs Trump election?\"\n",
    "    )\n",
    "    \n",
    "    return input_text, features\n",
    "\n",
    "def load_data(data_folder, variable_code, exclude_classes=None, include_classes=None):\n",
    "    \"\"\"\n",
    "    Loads question-response pairs for a given ANES variable code.\n",
    "    Uses only legitimate features that don't leak the outcome.\n",
    "    \"\"\"\n",
    "    examples = []\n",
    "    label_map = {}\n",
    "    next_label_id = 0\n",
    "    features_data = []\n",
    "\n",
    "    excluded_count = 0\n",
    "    included_count = 0\n",
    "    missing_answer_count = 0\n",
    "    not_included_count = 0\n",
    "    matched_count = 0\n",
    "\n",
    "    if exclude_classes is None:\n",
    "        exclude_classes = ['Inapplicable', 'Refused', \"Don't know\", 'Error', \"Don't know\"]\n",
    "\n",
    "    json_files = [f for f in os.listdir(data_folder) if f.endswith('.json')]\n",
    "    print(f\"Processing {len(json_files)} JSON files for variable {variable_code}\")\n",
    "\n",
    "    for i, fname in enumerate(json_files):\n",
    "        if i % 500 == 0:\n",
    "            print(f\"Progress: {i}/{len(json_files)} files processed\")\n",
    "\n",
    "        try:\n",
    "            with open(os.path.join(data_folder, fname)) as f:\n",
    "                respondent = json.load(f)\n",
    "        except (json.JSONDecodeError, FileNotFoundError):\n",
    "            continue\n",
    "\n",
    "        responses = respondent.get(\"responses\", [])\n",
    "        found = False\n",
    "        for item in responses:\n",
    "            if item.get(\"variable_code\") != variable_code:\n",
    "                continue\n",
    "\n",
    "            question = item.get(\"full_question_text\", \"\")\n",
    "            possible_answers = [opt[\"text\"] for opt in item.get(\"possible_answers\", [])]\n",
    "            respondent_answer = item.get(\"respondent_answer\", None)\n",
    "\n",
    "            if not respondent_answer:\n",
    "                missing_answer_count += 1\n",
    "                continue\n",
    "\n",
    "            if respondent_answer in exclude_classes:\n",
    "                excluded_count += 1\n",
    "                continue\n",
    "\n",
    "            if include_classes and respondent_answer not in include_classes:\n",
    "                not_included_count += 1\n",
    "                continue\n",
    "\n",
    "            included_count += 1\n",
    "\n",
    "            if respondent_answer not in label_map:\n",
    "                label_map[respondent_answer] = next_label_id\n",
    "                next_label_id += 1\n",
    "            label = label_map[respondent_answer]\n",
    "\n",
    "            # Extract legitimate features instead of leaky ones\n",
    "            input_text, features = extract_legitimate_features(responses)\n",
    "            \n",
    "            examples.append((input_text, label))\n",
    "            features_data.append(features)\n",
    "            matched_count += 1\n",
    "            found = True\n",
    "            break  # Only use first match per respondent\n",
    "\n",
    "    # Summary logging\n",
    "    print(f\"\\nüìä Summary for variable {variable_code}:\")\n",
    "    print(f\"  ‚û§ Total JSON files: {len(json_files)}\")\n",
    "    print(f\"  ‚û§ Valid examples collected: {matched_count}\")\n",
    "    print(f\"  ‚û§ Unique labels: {len(label_map)}\")\n",
    "    print(f\"  ‚û§ Skipped due to missing answers: {missing_answer_count}\")\n",
    "    print(f\"  ‚û§ Skipped due to exclusion list: {excluded_count}\")\n",
    "    print(f\"  ‚û§ Skipped (not in include_classes): {not_included_count}\")\n",
    "    if include_classes:\n",
    "        print(f\"  ‚û§ Included only: {include_classes}\")\n",
    "    print(f\"  ‚û§ Final label map: {label_map}\")\n",
    "\n",
    "    # Class distribution\n",
    "    label_counts = Counter([label for _, label in examples])\n",
    "    print(\"\\nüîç Class distribution (label IDs):\", label_counts)\n",
    "    for label, count in label_counts.items():\n",
    "        for key, val in label_map.items():\n",
    "            if val == label:\n",
    "                print(f\"  ‚û§ '{key}': {count} samples\")\n",
    "\n",
    "    return examples, label_map, features_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "93077f74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANESDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_len=256):\n",
    "        self.texts = list(texts)\n",
    "        self.labels = list(labels)\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_len = max_len\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        enc = self.tokenizer(\n",
    "            self.texts[idx],\n",
    "            truncation=True,\n",
    "            padding=\"max_length\",\n",
    "            max_length=self.max_len,\n",
    "            return_tensors=\"pt\",\n",
    "        )\n",
    "\n",
    "        return {\n",
    "            \"input_ids\": enc[\"input_ids\"].squeeze(0).long(),\n",
    "            \"attention_mask\": enc[\"attention_mask\"].squeeze(0).float(),\n",
    "            \"labels\": torch.tensor(self.labels[idx], dtype=torch.long),\n",
    "        }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bea9552b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class FocalLoss(nn.Module):\n",
    "    def __init__(self, alpha=None, gamma=2.0, reduction='mean'):\n",
    "        \"\"\"\n",
    "        alpha: 1D tensor of shape [num_classes] or None\n",
    "        gamma: focusing parameter\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.reduction = reduction\n",
    "\n",
    "    def forward(self, logits, targets):\n",
    "        \"\"\"\n",
    "        logits: Tensor[B, C]\n",
    "        targets: Tensor[B] with class indices 0 ‚â§ targets[i] < C\n",
    "        \"\"\"\n",
    "        # move class weights if provided\n",
    "        if self.alpha is not None:\n",
    "            self.alpha = self.alpha.to(logits.device)\n",
    "\n",
    "        # standard CE with no reduction ‚Üí [B]\n",
    "        ce = F.cross_entropy(logits, targets, weight=self.alpha, reduction='none')\n",
    "        pt = torch.exp(-ce)             # [B], pt = probability of the true class\n",
    "        loss = (1 - pt) ** self.gamma * ce\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return loss.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return loss.sum()\n",
    "        else:\n",
    "            return loss  # [B]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8f3db3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_legitimate_features(responses):\n",
    "    \"\"\"\n",
    "    Extract only legitimate, non-leaky features from the responses.\n",
    "    \"\"\"\n",
    "    features = {}\n",
    "    \n",
    "    # Helper to extract response safely\n",
    "    def extract_response(responses, code):\n",
    "        for r in responses:\n",
    "            if r[\"variable_code\"] == code:\n",
    "                ans = r.get(\"respondent_answer\")\n",
    "                if ans in ['Inapplicable', 'Refused', \"Don't know\", 'Error']:\n",
    "                    return \"NA\"\n",
    "                return str(ans)\n",
    "        return \"NA\"\n",
    "    \n",
    "    # Demographic features\n",
    "    features[\"political_interest\"] = extract_response(responses, \"V241004\")  # Political interest\n",
    "    features[\"campaign_interest\"] = extract_response(responses, \"V241005\")   # Campaign interest\n",
    "    \n",
    "    # Economic views (if available)\n",
    "    features[\"economic_views\"] = extract_response(responses, \"V241127\")\n",
    "    \n",
    "    # State/region information\n",
    "    features[\"state\"] = extract_response(responses, \"V241017\")\n",
    "    \n",
    "    # Media consumption (example)\n",
    "    features[\"media_consumption\"] = extract_response(responses, \"V241201\")\n",
    "    \n",
    "    # Convert features to a single text representation\n",
    "    input_text = (\n",
    "        f\"Political interest: {features['political_interest']}\\n\"\n",
    "        f\"Campaign interest: {features['campaign_interest']}\\n\"\n",
    "        f\"Economic views: {features['economic_views']}\\n\"\n",
    "        f\"State: {features['state']}\\n\"\n",
    "        f\"Media consumption: {features['media_consumption']}\\n\"\n",
    "        f\"Q: Who would this respondent vote for in a Harris vs Trump election?\"\n",
    "    )\n",
    "    \n",
    "    return input_text, features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "66df44cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, loader, optimizer, scheduler, device, loss_fn):\n",
    "    model.train()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "\n",
    "    for batch in loader:\n",
    "        optimizer.zero_grad()\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        labels = batch['labels'].to(device)\n",
    "\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        logits = outputs.logits  # [B, C]\n",
    "\n",
    "        loss = loss_fn(logits, labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item() * labels.size(0)\n",
    "        preds = torch.argmax(logits, dim=1)\n",
    "        correct += (preds == labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    acc = correct / total\n",
    "    return avg_loss, acc\n",
    "\n",
    "def eval_epoch(model, loader, device, loss_fn):\n",
    "    model.eval()\n",
    "    total_loss, correct, total = 0.0, 0, 0\n",
    "    all_logits, all_preds, all_labels = [], [], []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch in loader:\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            labels = batch['labels'].to(device)\n",
    "\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "            logits = outputs.logits\n",
    "\n",
    "            loss = loss_fn(logits, labels)\n",
    "            total_loss += loss.item() * labels.size(0)\n",
    "\n",
    "            preds = torch.argmax(logits, dim=1)\n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_logits.append(logits.cpu())\n",
    "            all_preds.append(preds.cpu())\n",
    "            all_labels.append(labels.cpu())\n",
    "\n",
    "    avg_loss = total_loss / total\n",
    "    acc = correct / total\n",
    "\n",
    "    all_logits = torch.cat(all_logits)\n",
    "    all_preds = torch.cat(all_preds)\n",
    "    all_labels = torch.cat(all_labels)\n",
    "    return avg_loss, acc, all_logits, all_preds, all_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "894f3549",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_class_distribution(labels, label_map):\n",
    "    \"\"\"Print the distribution of classes in the dataset.\"\"\"\n",
    "    from collections import Counter\n",
    "    reverse_label_map = {v: k for k, v in label_map.items()}\n",
    "    \n",
    "    label_counts = Counter(labels)\n",
    "    print(\"\\nClass Distribution:\")\n",
    "    print(\"-\" * 50)\n",
    "    for label_id, count in sorted(label_counts.items()):\n",
    "        class_name = reverse_label_map.get(label_id, f\"Unknown_{label_id}\")\n",
    "        percentage = (count / len(labels)) * 100\n",
    "        print(f\"{class_name}: {count} ({percentage:.1f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "28137e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_threshold_and_report(val_logits, val_true, label_map, threshold=0.5):\n",
    "    \"\"\"\n",
    "    Apply threshold-based prediction for binary classification and print report + confusion matrix.\n",
    "    \"\"\"\n",
    "    # Convert logits to probabilities\n",
    "    probs = torch.softmax(val_logits, dim=-1).cpu().numpy()\n",
    "\n",
    "    # Get class indices\n",
    "    idx_to_label = {v: k for k, v in label_map.items()}\n",
    "    class_names = [idx_to_label[i] for i in range(len(idx_to_label))]\n",
    "    \n",
    "    # For binary classification, we can use the probability of class 1\n",
    "    # If we have more than 2 classes, this needs to be adjusted\n",
    "    if len(class_names) == 2:\n",
    "        # Get index for the second class (typically index 1)\n",
    "        class_idx = 1\n",
    "        class_probs = probs[:, class_idx]\n",
    "        \n",
    "        # Binary prediction based on threshold\n",
    "        preds = (class_probs > threshold).astype(int)\n",
    "        \n",
    "        # Convert true labels to binary format matching our predictions\n",
    "        binary_true = (val_true.numpy() == class_idx).astype(int)\n",
    "        \n",
    "        # Print classification report\n",
    "        print(f\"\\n‚úÖ Classification Report (Thresholded @ {threshold:.2f}):\")\n",
    "        print(classification_report(binary_true, preds, target_names=class_names, zero_division=0))\n",
    "        \n",
    "        # Plot confusion matrix\n",
    "        cm = confusion_matrix(binary_true, preds)\n",
    "        plt.figure(figsize=(8, 6))\n",
    "        sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_names, yticklabels=class_names)\n",
    "        plt.xlabel(\"Predicted\")\n",
    "        plt.ylabel(\"Actual\")\n",
    "        plt.title(f\"Confusion Matrix (Threshold: {threshold:.2f})\")\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(f'confusion_matrix_threshold_{threshold:.2f}.png')\n",
    "        plt.close()\n",
    "        \n",
    "        # Calculate AUC\n",
    "        try:\n",
    "            auc = roc_auc_score(binary_true, class_probs)\n",
    "            print(f\"AUC: {auc:.4f}\")\n",
    "        except:\n",
    "            print(\"Could not calculate AUC\")\n",
    "    else:\n",
    "        print(\"This function is designed for binary classification only.\")\n",
    "\n",
    "def apply_sampling_strategy(X_train, y_train, strategy='smote'):\n",
    "    \"\"\"\n",
    "    Apply sampling strategy to address class imbalance.\n",
    "    \n",
    "    Parameters:\n",
    "    - X_train: Training features\n",
    "    - y_train: Training labels\n",
    "    - strategy: Sampling strategy ('smote', 'undersample', 'none')\n",
    "    \n",
    "    Returns:\n",
    "    - Resampled X_train, y_train\n",
    "    \"\"\"\n",
    "    if strategy == 'none':\n",
    "        return X_train, y_train\n",
    "    \n",
    "    if strategy == 'smote':\n",
    "        print(\"Applying SMOTE oversampling...\")\n",
    "        smote = SMOTE(random_state=42)\n",
    "        X_resampled, y_resampled = smote.fit_resample(X_train, y_train)\n",
    "        return X_resampled, y_resampled\n",
    "    \n",
    "    if strategy == 'undersample':\n",
    "        print(\"Applying random undersampling...\")\n",
    "        rus = RandomUnderSampler(random_state=42)\n",
    "        X_resampled, y_resampled = rus.fit_resample(X_train, y_train)\n",
    "        return X_resampled, y_resampled\n",
    "    \n",
    "    raise ValueError(f\"Unknown sampling strategy: {strategy}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a57e2385",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "Running with sampling strategy: none\n",
      "======================================================================\n",
      "Processing 3349 JSON files for variable V241049\n",
      "Progress: 0/3349 files processed\n",
      "Progress: 500/3349 files processed\n",
      "Progress: 1000/3349 files processed\n",
      "Progress: 1500/3349 files processed\n",
      "Progress: 2000/3349 files processed\n",
      "Progress: 2500/3349 files processed\n",
      "Progress: 3000/3349 files processed\n",
      "\n",
      "üìä Summary for variable V241049:\n",
      "  ‚û§ Total JSON files: 3349\n",
      "  ‚û§ Valid examples collected: 2959\n",
      "  ‚û§ Unique labels: 2\n",
      "  ‚û§ Skipped due to missing answers: 0\n",
      "  ‚û§ Skipped due to exclusion list: 34\n",
      "  ‚û§ Skipped (not in include_classes): 356\n",
      "  ‚û§ Included only: ['Donald Trump', 'Kamala Harris']\n",
      "  ‚û§ Final label map: {'Donald Trump': 0, 'Kamala Harris': 1}\n",
      "\n",
      "üîç Class distribution (label IDs): Counter({1: 1623, 0: 1336})\n",
      "  ‚û§ 'Donald Trump': 1336 samples\n",
      "  ‚û§ 'Kamala Harris': 1623 samples\n",
      "\n",
      "Class Distribution:\n",
      "--------------------------------------------------\n",
      "Donald Trump: 1336 (45.2%)\n",
      "Kamala Harris: 1623 (54.8%)\n",
      "\n",
      "==================================================\n",
      "Fold 1/5\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1223, Acc: 0.7440\n",
      "  Val   - Loss: 0.1002, Acc: 0.8514\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0956, Acc: 0.8496\n",
      "  Val   - Loss: 0.0989, Acc: 0.8547\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0912, Acc: 0.8568\n",
      "  Val   - Loss: 0.0902, Acc: 0.8547\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0886, Acc: 0.8559\n",
      "  Val   - Loss: 0.0909, Acc: 0.8547\n",
      "\n",
      "Evaluating with different thresholds:\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.30):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.96      0.70      0.81       268\n",
      "Kamala Harris       0.80      0.98      0.88       324\n",
      "\n",
      "     accuracy                           0.85       592\n",
      "    macro avg       0.88      0.84      0.84       592\n",
      " weighted avg       0.87      0.85      0.85       592\n",
      "\n",
      "AUC: 0.9368\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.40):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.89      0.82      0.85       268\n",
      "Kamala Harris       0.86      0.92      0.89       324\n",
      "\n",
      "     accuracy                           0.87       592\n",
      "    macro avg       0.88      0.87      0.87       592\n",
      " weighted avg       0.87      0.87      0.87       592\n",
      "\n",
      "AUC: 0.9368\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.50):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.82      0.87      0.84       268\n",
      "Kamala Harris       0.89      0.84      0.86       324\n",
      "\n",
      "     accuracy                           0.85       592\n",
      "    macro avg       0.85      0.86      0.85       592\n",
      " weighted avg       0.86      0.85      0.85       592\n",
      "\n",
      "AUC: 0.9368\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.60):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.67      0.97      0.79       268\n",
      "Kamala Harris       0.96      0.60      0.74       324\n",
      "\n",
      "     accuracy                           0.77       592\n",
      "    macro avg       0.81      0.78      0.76       592\n",
      " weighted avg       0.82      0.77      0.76       592\n",
      "\n",
      "AUC: 0.9368\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.70):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.67      0.97      0.79       268\n",
      "Kamala Harris       0.96      0.60      0.74       324\n",
      "\n",
      "     accuracy                           0.77       592\n",
      "    macro avg       0.81      0.78      0.76       592\n",
      " weighted avg       0.82      0.77      0.76       592\n",
      "\n",
      "AUC: 0.9368\n",
      "\n",
      "==================================================\n",
      "Fold 2/5\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1250, Acc: 0.7406\n",
      "  Val   - Loss: 0.1106, Acc: 0.8007\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0930, Acc: 0.8411\n",
      "  Val   - Loss: 0.1138, Acc: 0.8429\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0894, Acc: 0.8538\n",
      "  Val   - Loss: 0.1139, Acc: 0.8429\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0870, Acc: 0.8564\n",
      "  Val   - Loss: 0.1024, Acc: 0.8429\n",
      "\n",
      "Evaluating with different thresholds:\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.30):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.95      0.62      0.75       267\n",
      "Kamala Harris       0.76      0.97      0.85       325\n",
      "\n",
      "     accuracy                           0.81       592\n",
      "    macro avg       0.85      0.80      0.80       592\n",
      " weighted avg       0.84      0.81      0.80       592\n",
      "\n",
      "AUC: 0.9225\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.40):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.95      0.62      0.75       267\n",
      "Kamala Harris       0.76      0.97      0.85       325\n",
      "\n",
      "     accuracy                           0.81       592\n",
      "    macro avg       0.85      0.80      0.80       592\n",
      " weighted avg       0.84      0.81      0.80       592\n",
      "\n",
      "AUC: 0.9225\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.50):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.80      0.88      0.83       267\n",
      "Kamala Harris       0.89      0.82      0.85       325\n",
      "\n",
      "     accuracy                           0.84       592\n",
      "    macro avg       0.84      0.85      0.84       592\n",
      " weighted avg       0.85      0.84      0.84       592\n",
      "\n",
      "AUC: 0.9225\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.60):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.70      0.93      0.80       267\n",
      "Kamala Harris       0.92      0.67      0.77       325\n",
      "\n",
      "     accuracy                           0.79       592\n",
      "    macro avg       0.81      0.80      0.78       592\n",
      " weighted avg       0.82      0.79      0.78       592\n",
      "\n",
      "AUC: 0.9225\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.70):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.66      0.97      0.79       267\n",
      "Kamala Harris       0.96      0.59      0.73       325\n",
      "\n",
      "     accuracy                           0.76       592\n",
      "    macro avg       0.81      0.78      0.76       592\n",
      " weighted avg       0.82      0.76      0.76       592\n",
      "\n",
      "AUC: 0.9225\n",
      "\n",
      "==================================================\n",
      "Fold 3/5\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1242, Acc: 0.7410\n",
      "  Val   - Loss: 0.1044, Acc: 0.8699\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0926, Acc: 0.8373\n",
      "  Val   - Loss: 0.0889, Acc: 0.8564\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0909, Acc: 0.8526\n",
      "  Val   - Loss: 0.0849, Acc: 0.8497\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0901, Acc: 0.8555\n",
      "  Val   - Loss: 0.0851, Acc: 0.8564\n",
      "\n",
      "Evaluating with different thresholds:\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.30):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.97      0.65      0.78       267\n",
      "Kamala Harris       0.77      0.98      0.87       325\n",
      "\n",
      "     accuracy                           0.83       592\n",
      "    macro avg       0.87      0.82      0.82       592\n",
      " weighted avg       0.86      0.83      0.83       592\n",
      "\n",
      "AUC: 0.9395\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.40):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.93      0.69      0.79       267\n",
      "Kamala Harris       0.79      0.96      0.87       325\n",
      "\n",
      "     accuracy                           0.84       592\n",
      "    macro avg       0.86      0.82      0.83       592\n",
      " weighted avg       0.85      0.84      0.83       592\n",
      "\n",
      "AUC: 0.9395\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.50):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.81      0.90      0.85       267\n",
      "Kamala Harris       0.91      0.82      0.86       325\n",
      "\n",
      "     accuracy                           0.86       592\n",
      "    macro avg       0.86      0.86      0.86       592\n",
      " weighted avg       0.86      0.86      0.86       592\n",
      "\n",
      "AUC: 0.9395\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.60):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.71      0.96      0.81       267\n",
      "Kamala Harris       0.95      0.68      0.79       325\n",
      "\n",
      "     accuracy                           0.80       592\n",
      "    macro avg       0.83      0.82      0.80       592\n",
      " weighted avg       0.84      0.80      0.80       592\n",
      "\n",
      "AUC: 0.9395\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.70):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.67      0.97      0.79       267\n",
      "Kamala Harris       0.96      0.61      0.75       325\n",
      "\n",
      "     accuracy                           0.77       592\n",
      "    macro avg       0.82      0.79      0.77       592\n",
      " weighted avg       0.83      0.77      0.77       592\n",
      "\n",
      "AUC: 0.9395\n",
      "\n",
      "==================================================\n",
      "Fold 4/5\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1259, Acc: 0.7220\n",
      "  Val   - Loss: 0.0849, Acc: 0.8750\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0977, Acc: 0.8378\n",
      "  Val   - Loss: 0.0751, Acc: 0.8750\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0928, Acc: 0.8411\n",
      "  Val   - Loss: 0.0799, Acc: 0.8750\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0914, Acc: 0.8471\n",
      "  Val   - Loss: 0.0784, Acc: 0.8699\n",
      "\n",
      "Evaluating with different thresholds:\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.30):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.97      0.71      0.82       267\n",
      "Kamala Harris       0.80      0.98      0.89       325\n",
      "\n",
      "     accuracy                           0.86       592\n",
      "    macro avg       0.89      0.85      0.85       592\n",
      " weighted avg       0.88      0.86      0.86       592\n",
      "\n",
      "AUC: 0.9470\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.40):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.89      0.80      0.84       267\n",
      "Kamala Harris       0.85      0.92      0.88       325\n",
      "\n",
      "     accuracy                           0.87       592\n",
      "    macro avg       0.87      0.86      0.86       592\n",
      " weighted avg       0.87      0.87      0.87       592\n",
      "\n",
      "AUC: 0.9470\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.50):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.82      0.91      0.86       267\n",
      "Kamala Harris       0.92      0.83      0.88       325\n",
      "\n",
      "     accuracy                           0.87       592\n",
      "    macro avg       0.87      0.87      0.87       592\n",
      " weighted avg       0.88      0.87      0.87       592\n",
      "\n",
      "AUC: 0.9470\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.60):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.70      0.97      0.81       267\n",
      "Kamala Harris       0.96      0.65      0.78       325\n",
      "\n",
      "     accuracy                           0.80       592\n",
      "    macro avg       0.83      0.81      0.79       592\n",
      " weighted avg       0.84      0.80      0.79       592\n",
      "\n",
      "AUC: 0.9470\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.70):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.68      0.98      0.80       267\n",
      "Kamala Harris       0.98      0.62      0.76       325\n",
      "\n",
      "     accuracy                           0.79       592\n",
      "    macro avg       0.83      0.80      0.78       592\n",
      " weighted avg       0.84      0.79      0.78       592\n",
      "\n",
      "AUC: 0.9470\n",
      "\n",
      "==================================================\n",
      "Fold 5/5\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1261, Acc: 0.7373\n",
      "  Val   - Loss: 0.1102, Acc: 0.8190\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0950, Acc: 0.8573\n",
      "  Val   - Loss: 0.0955, Acc: 0.8426\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0888, Acc: 0.8619\n",
      "  Val   - Loss: 0.0942, Acc: 0.8443\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0881, Acc: 0.8615\n",
      "  Val   - Loss: 0.0911, Acc: 0.8443\n",
      "\n",
      "Evaluating with different thresholds:\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.30):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.95      0.63      0.76       267\n",
      "Kamala Harris       0.76      0.97      0.85       324\n",
      "\n",
      "     accuracy                           0.82       591\n",
      "    macro avg       0.86      0.80      0.81       591\n",
      " weighted avg       0.85      0.82      0.81       591\n",
      "\n",
      "AUC: 0.9278\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.40):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.95      0.63      0.76       267\n",
      "Kamala Harris       0.76      0.97      0.85       324\n",
      "\n",
      "     accuracy                           0.82       591\n",
      "    macro avg       0.86      0.80      0.81       591\n",
      " weighted avg       0.85      0.82      0.81       591\n",
      "\n",
      "AUC: 0.9278\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.50):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.80      0.87      0.83       267\n",
      "Kamala Harris       0.88      0.82      0.85       324\n",
      "\n",
      "     accuracy                           0.84       591\n",
      "    macro avg       0.84      0.85      0.84       591\n",
      " weighted avg       0.85      0.84      0.84       591\n",
      "\n",
      "AUC: 0.9278\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.60):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.68      0.98      0.80       267\n",
      "Kamala Harris       0.97      0.61      0.75       324\n",
      "\n",
      "     accuracy                           0.78       591\n",
      "    macro avg       0.82      0.80      0.78       591\n",
      " weighted avg       0.84      0.78      0.77       591\n",
      "\n",
      "AUC: 0.9278\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.70):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.68      0.98      0.80       267\n",
      "Kamala Harris       0.97      0.61      0.75       324\n",
      "\n",
      "     accuracy                           0.78       591\n",
      "    macro avg       0.82      0.80      0.78       591\n",
      " weighted avg       0.84      0.78      0.77       591\n",
      "\n",
      "AUC: 0.9278\n",
      "\n",
      "==================================================\n",
      "Cross-validation results:\n",
      "==================================================\n",
      "Average validation accuracy: 0.8574\n",
      "Average validation loss: 0.0993\n",
      "\n",
      "==================================================\n",
      "Training final model on all data:\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1261, Acc: 0.7519\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0952, Acc: 0.8469\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0900, Acc: 0.8530\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0892, Acc: 0.8547\n",
      "\n",
      "‚úÖ Training completed.\n",
      "\n",
      "Model saved to 'anes_classifier_model_legitimate_features.pt'\n",
      "\n",
      "======================================================================\n",
      "Running with sampling strategy: smote\n",
      "======================================================================\n",
      "Processing 3349 JSON files for variable V241049\n",
      "Progress: 0/3349 files processed\n",
      "Progress: 500/3349 files processed\n",
      "Progress: 1000/3349 files processed\n",
      "Progress: 1500/3349 files processed\n",
      "Progress: 2000/3349 files processed\n",
      "Progress: 2500/3349 files processed\n",
      "Progress: 3000/3349 files processed\n",
      "\n",
      "üìä Summary for variable V241049:\n",
      "  ‚û§ Total JSON files: 3349\n",
      "  ‚û§ Valid examples collected: 2959\n",
      "  ‚û§ Unique labels: 2\n",
      "  ‚û§ Skipped due to missing answers: 0\n",
      "  ‚û§ Skipped due to exclusion list: 34\n",
      "  ‚û§ Skipped (not in include_classes): 356\n",
      "  ‚û§ Included only: ['Donald Trump', 'Kamala Harris']\n",
      "  ‚û§ Final label map: {'Donald Trump': 0, 'Kamala Harris': 1}\n",
      "\n",
      "üîç Class distribution (label IDs): Counter({1: 1623, 0: 1336})\n",
      "  ‚û§ 'Donald Trump': 1336 samples\n",
      "  ‚û§ 'Kamala Harris': 1623 samples\n",
      "\n",
      "Class Distribution:\n",
      "--------------------------------------------------\n",
      "Donald Trump: 1336 (45.2%)\n",
      "Kamala Harris: 1623 (54.8%)\n",
      "\n",
      "==================================================\n",
      "Fold 1/5\n",
      "==================================================\n",
      "Applying SMOTE oversampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1267, Acc: 0.7841\n",
      "  Val   - Loss: 0.1281, Acc: 0.8547\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0924, Acc: 0.8545\n",
      "  Val   - Loss: 0.0935, Acc: 0.8547\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0879, Acc: 0.8610\n",
      "  Val   - Loss: 0.0982, Acc: 0.8598\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0878, Acc: 0.8618\n",
      "  Val   - Loss: 0.0908, Acc: 0.8547\n",
      "\n",
      "Evaluating with different thresholds:\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.30):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.96      0.70      0.81       268\n",
      "Kamala Harris       0.80      0.98      0.88       324\n",
      "\n",
      "     accuracy                           0.85       592\n",
      "    macro avg       0.88      0.84      0.84       592\n",
      " weighted avg       0.87      0.85      0.85       592\n",
      "\n",
      "AUC: 0.9335\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.40):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.96      0.70      0.81       268\n",
      "Kamala Harris       0.80      0.98      0.88       324\n",
      "\n",
      "     accuracy                           0.85       592\n",
      "    macro avg       0.88      0.84      0.84       592\n",
      " weighted avg       0.87      0.85      0.85       592\n",
      "\n",
      "AUC: 0.9335\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.50):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.85      0.83      0.84       268\n",
      "Kamala Harris       0.86      0.88      0.87       324\n",
      "\n",
      "     accuracy                           0.85       592\n",
      "    macro avg       0.85      0.85      0.85       592\n",
      " weighted avg       0.85      0.85      0.85       592\n",
      "\n",
      "AUC: 0.9335\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.60):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.68      0.96      0.79       268\n",
      "Kamala Harris       0.95      0.62      0.75       324\n",
      "\n",
      "     accuracy                           0.78       592\n",
      "    macro avg       0.81      0.79      0.77       592\n",
      " weighted avg       0.83      0.78      0.77       592\n",
      "\n",
      "AUC: 0.9335\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.70):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.65      0.97      0.78       268\n",
      "Kamala Harris       0.95      0.58      0.72       324\n",
      "\n",
      "     accuracy                           0.75       592\n",
      "    macro avg       0.80      0.77      0.75       592\n",
      " weighted avg       0.82      0.75      0.75       592\n",
      "\n",
      "AUC: 0.9335\n",
      "\n",
      "==================================================\n",
      "Fold 2/5\n",
      "==================================================\n",
      "Applying SMOTE oversampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1193, Acc: 0.7581\n",
      "  Val   - Loss: 0.1051, Acc: 0.8446\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0920, Acc: 0.8463\n",
      "  Val   - Loss: 0.0990, Acc: 0.8497\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0863, Acc: 0.8613\n",
      "  Val   - Loss: 0.1055, Acc: 0.8480\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0829, Acc: 0.8586\n",
      "  Val   - Loss: 0.1018, Acc: 0.8615\n",
      "\n",
      "Evaluating with different thresholds:\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.30):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.95      0.62      0.75       267\n",
      "Kamala Harris       0.76      0.97      0.85       325\n",
      "\n",
      "     accuracy                           0.81       592\n",
      "    macro avg       0.85      0.80      0.80       592\n",
      " weighted avg       0.84      0.81      0.80       592\n",
      "\n",
      "AUC: 0.9233\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.40):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.95      0.62      0.75       267\n",
      "Kamala Harris       0.76      0.97      0.85       325\n",
      "\n",
      "     accuracy                           0.81       592\n",
      "    macro avg       0.85      0.80      0.80       592\n",
      " weighted avg       0.84      0.81      0.80       592\n",
      "\n",
      "AUC: 0.9233\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.50):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.88      0.81      0.84       267\n",
      "Kamala Harris       0.85      0.91      0.88       325\n",
      "\n",
      "     accuracy                           0.86       592\n",
      "    macro avg       0.86      0.86      0.86       592\n",
      " weighted avg       0.86      0.86      0.86       592\n",
      "\n",
      "AUC: 0.9233\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.60):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.72      0.92      0.81       267\n",
      "Kamala Harris       0.92      0.70      0.80       325\n",
      "\n",
      "     accuracy                           0.80       592\n",
      "    macro avg       0.82      0.81      0.80       592\n",
      " weighted avg       0.83      0.80      0.80       592\n",
      "\n",
      "AUC: 0.9233\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.70):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.67      0.94      0.78       267\n",
      "Kamala Harris       0.93      0.62      0.74       325\n",
      "\n",
      "     accuracy                           0.76       592\n",
      "    macro avg       0.80      0.78      0.76       592\n",
      " weighted avg       0.81      0.76      0.76       592\n",
      "\n",
      "AUC: 0.9233\n",
      "\n",
      "==================================================\n",
      "Fold 3/5\n",
      "==================================================\n",
      "Applying SMOTE oversampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1286, Acc: 0.7338\n",
      "  Val   - Loss: 0.0822, Acc: 0.8699\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0943, Acc: 0.8502\n",
      "  Val   - Loss: 0.0866, Acc: 0.8564\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0919, Acc: 0.8459\n",
      "  Val   - Loss: 0.0885, Acc: 0.8564\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0894, Acc: 0.8536\n",
      "  Val   - Loss: 0.0868, Acc: 0.8564\n",
      "\n",
      "Evaluating with different thresholds:\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.30):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.97      0.65      0.78       267\n",
      "Kamala Harris       0.77      0.98      0.87       325\n",
      "\n",
      "     accuracy                           0.83       592\n",
      "    macro avg       0.87      0.82      0.82       592\n",
      " weighted avg       0.86      0.83      0.83       592\n",
      "\n",
      "AUC: 0.9350\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.40):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.97      0.66      0.78       267\n",
      "Kamala Harris       0.78      0.98      0.87       325\n",
      "\n",
      "     accuracy                           0.84       592\n",
      "    macro avg       0.87      0.82      0.83       592\n",
      " weighted avg       0.86      0.84      0.83       592\n",
      "\n",
      "AUC: 0.9350\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.50):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.81      0.90      0.85       267\n",
      "Kamala Harris       0.91      0.82      0.86       325\n",
      "\n",
      "     accuracy                           0.86       592\n",
      "    macro avg       0.86      0.86      0.86       592\n",
      " weighted avg       0.86      0.86      0.86       592\n",
      "\n",
      "AUC: 0.9350\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.60):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.67      0.97      0.79       267\n",
      "Kamala Harris       0.96      0.61      0.75       325\n",
      "\n",
      "     accuracy                           0.77       592\n",
      "    macro avg       0.82      0.79      0.77       592\n",
      " weighted avg       0.83      0.77      0.77       592\n",
      "\n",
      "AUC: 0.9350\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.70):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.67      0.97      0.79       267\n",
      "Kamala Harris       0.96      0.61      0.75       325\n",
      "\n",
      "     accuracy                           0.77       592\n",
      "    macro avg       0.82      0.79      0.77       592\n",
      " weighted avg       0.83      0.77      0.77       592\n",
      "\n",
      "AUC: 0.9350\n",
      "\n",
      "==================================================\n",
      "Fold 4/5\n",
      "==================================================\n",
      "Applying SMOTE oversampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1316, Acc: 0.7219\n",
      "  Val   - Loss: 0.0789, Acc: 0.8666\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0991, Acc: 0.8467\n",
      "  Val   - Loss: 0.0758, Acc: 0.8666\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0925, Acc: 0.8405\n",
      "  Val   - Loss: 0.0771, Acc: 0.8666\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0886, Acc: 0.8567\n",
      "  Val   - Loss: 0.0811, Acc: 0.8666\n",
      "\n",
      "Evaluating with different thresholds:\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.30):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.97      0.71      0.82       267\n",
      "Kamala Harris       0.81      0.98      0.88       325\n",
      "\n",
      "     accuracy                           0.86       592\n",
      "    macro avg       0.89      0.85      0.85       592\n",
      " weighted avg       0.88      0.86      0.86       592\n",
      "\n",
      "AUC: 0.9465\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.40):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.89      0.79      0.83       267\n",
      "Kamala Harris       0.84      0.92      0.88       325\n",
      "\n",
      "     accuracy                           0.86       592\n",
      "    macro avg       0.86      0.85      0.85       592\n",
      " weighted avg       0.86      0.86      0.86       592\n",
      "\n",
      "AUC: 0.9465\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.50):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.88      0.82      0.85       267\n",
      "Kamala Harris       0.86      0.91      0.88       325\n",
      "\n",
      "     accuracy                           0.87       592\n",
      "    macro avg       0.87      0.86      0.86       592\n",
      " weighted avg       0.87      0.87      0.87       592\n",
      "\n",
      "AUC: 0.9465\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.60):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.68      0.98      0.80       267\n",
      "Kamala Harris       0.98      0.62      0.76       325\n",
      "\n",
      "     accuracy                           0.79       592\n",
      "    macro avg       0.83      0.80      0.78       592\n",
      " weighted avg       0.84      0.79      0.78       592\n",
      "\n",
      "AUC: 0.9465\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.70):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.67      0.98      0.79       267\n",
      "Kamala Harris       0.97      0.60      0.74       325\n",
      "\n",
      "     accuracy                           0.77       592\n",
      "    macro avg       0.82      0.79      0.77       592\n",
      " weighted avg       0.84      0.77      0.76       592\n",
      "\n",
      "AUC: 0.9465\n",
      "\n",
      "==================================================\n",
      "Fold 5/5\n",
      "==================================================\n",
      "Applying SMOTE oversampling...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1202, Acc: 0.7675\n",
      "  Val   - Loss: 0.0997, Acc: 0.8460\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0961, Acc: 0.8487\n",
      "  Val   - Loss: 0.0953, Acc: 0.8443\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0922, Acc: 0.8549\n",
      "  Val   - Loss: 0.0983, Acc: 0.8443\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0913, Acc: 0.8603\n",
      "  Val   - Loss: 0.0940, Acc: 0.8443\n",
      "\n",
      "Evaluating with different thresholds:\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.30):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.95      0.63      0.76       267\n",
      "Kamala Harris       0.76      0.97      0.85       324\n",
      "\n",
      "     accuracy                           0.82       591\n",
      "    macro avg       0.86      0.80      0.81       591\n",
      " weighted avg       0.85      0.82      0.81       591\n",
      "\n",
      "AUC: 0.9288\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.40):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.95      0.63      0.76       267\n",
      "Kamala Harris       0.76      0.97      0.85       324\n",
      "\n",
      "     accuracy                           0.82       591\n",
      "    macro avg       0.86      0.80      0.81       591\n",
      " weighted avg       0.85      0.82      0.81       591\n",
      "\n",
      "AUC: 0.9288\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.50):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.80      0.87      0.83       267\n",
      "Kamala Harris       0.88      0.82      0.85       324\n",
      "\n",
      "     accuracy                           0.84       591\n",
      "    macro avg       0.84      0.85      0.84       591\n",
      " weighted avg       0.85      0.84      0.84       591\n",
      "\n",
      "AUC: 0.9288\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.60):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.80      0.87      0.83       267\n",
      "Kamala Harris       0.88      0.82      0.85       324\n",
      "\n",
      "     accuracy                           0.84       591\n",
      "    macro avg       0.84      0.85      0.84       591\n",
      " weighted avg       0.85      0.84      0.84       591\n",
      "\n",
      "AUC: 0.9288\n",
      "\n",
      "‚úÖ Classification Report (Thresholded @ 0.70):\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      " Donald Trump       0.68      0.98      0.80       267\n",
      "Kamala Harris       0.97      0.61      0.75       324\n",
      "\n",
      "     accuracy                           0.78       591\n",
      "    macro avg       0.82      0.80      0.78       591\n",
      " weighted avg       0.84      0.78      0.77       591\n",
      "\n",
      "AUC: 0.9288\n",
      "\n",
      "==================================================\n",
      "Cross-validation results:\n",
      "==================================================\n",
      "Average validation accuracy: 0.8608\n",
      "Average validation loss: 0.0922\n",
      "\n",
      "==================================================\n",
      "Training final model on all data:\n",
      "==================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaForSequenceClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.dense.bias', 'classifier.dense.weight', 'classifier.out_proj.bias', 'classifier.out_proj.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 1\n",
      "  Train - Loss: 0.1236, Acc: 0.7472\n",
      "\n",
      "Epoch 2\n",
      "  Train - Loss: 0.0964, Acc: 0.8462\n",
      "\n",
      "Epoch 3\n",
      "  Train - Loss: 0.0928, Acc: 0.8466\n",
      "\n",
      "Epoch 4\n",
      "  Train - Loss: 0.0880, Acc: 0.8516\n",
      "\n",
      "‚úÖ Training completed.\n",
      "\n",
      "Model saved to 'anes_classifier_model_legitimate_features.pt'\n"
     ]
    }
   ],
   "source": [
    "def main(data_folder, variable_code=\"V241049\", sampling_strategy='smote'):\n",
    "    # Target variable and label filtering\n",
    "    # V241049 is \"WHO WOULD R VOTE FOR: HARRIS VS TRUMP\"\n",
    "    include_classes = ['Donald Trump', 'Kamala Harris']\n",
    "\n",
    "    # Load data with legitimate features\n",
    "    examples, label_map, features_data = load_data(data_folder, variable_code, include_classes=include_classes)\n",
    "\n",
    "    # Split texts and labels\n",
    "    texts = [ex[0] for ex in examples]\n",
    "    labels = [ex[1] for ex in examples]\n",
    "\n",
    "    # Print class distribution\n",
    "    print_class_distribution(labels, label_map)\n",
    "\n",
    "    # Initialize tokenizer\n",
    "    tokenizer = RobertaTokenizer.from_pretrained(\"roberta-base\")\n",
    "    \n",
    "    # Implement k-fold cross-validation\n",
    "    n_splits = 5\n",
    "    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    \n",
    "    fold_results = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(skf.split(texts, labels)):\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Fold {fold+1}/{n_splits}\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        # Split data\n",
    "        train_texts = [texts[i] for i in train_idx]\n",
    "        train_labels = [labels[i] for i in train_idx]\n",
    "        val_texts = [texts[i] for i in val_idx]\n",
    "        val_labels = [labels[i] for i in val_idx]\n",
    "        \n",
    "        # Apply sampling strategy if needed\n",
    "        if sampling_strategy != 'none':\n",
    "            # For text data, we need to create a simple numerical representation for SMOTE\n",
    "            # This is just for sampling purposes\n",
    "            from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "            vectorizer = TfidfVectorizer(max_features=100)\n",
    "            X_train_vec = vectorizer.fit_transform(train_texts).toarray()\n",
    "            \n",
    "            # Apply sampling\n",
    "            X_train_resampled, y_train_resampled = apply_sampling_strategy(\n",
    "                X_train_vec, train_labels, strategy=sampling_strategy\n",
    "            )\n",
    "            \n",
    "            # Map back to texts (for oversampling, we'll have duplicates)\n",
    "            # For undersampling, we'll have fewer samples\n",
    "            if sampling_strategy == 'undersample':\n",
    "                # Get indices of remaining samples\n",
    "                remaining_indices = []\n",
    "                for i, label in enumerate(train_labels):\n",
    "                    if label in y_train_resampled:\n",
    "                        remaining_indices.append(i)\n",
    "                        y_train_resampled.remove(label)\n",
    "                \n",
    "                train_texts = [train_texts[i] for i in remaining_indices]\n",
    "                train_labels = [train_labels[i] for i in remaining_indices]\n",
    "            else:\n",
    "                # For SMOTE, we can't map back to original texts\n",
    "                # Instead, we'll duplicate existing texts based on the resampled labels\n",
    "                class_counts = Counter(y_train_resampled)\n",
    "                original_counts = Counter(train_labels)\n",
    "                \n",
    "                # Calculate how many samples to add for each class\n",
    "                to_add = {cls: count - original_counts.get(cls, 0) for cls, count in class_counts.items()}\n",
    "                \n",
    "                # Get indices for each class\n",
    "                class_indices = {cls: [] for cls in to_add.keys()}\n",
    "                for i, label in enumerate(train_labels):\n",
    "                    if label in class_indices:\n",
    "                        class_indices[label].append(i)\n",
    "                \n",
    "                # Add duplicates\n",
    "                for cls, count in to_add.items():\n",
    "                    if count <= 0:\n",
    "                        continue\n",
    "                    \n",
    "                    indices = class_indices[cls]\n",
    "                    if not indices:\n",
    "                        continue\n",
    "                    \n",
    "                    # Randomly select indices to duplicate\n",
    "                    import random\n",
    "                    random.seed(42)\n",
    "                    duplicate_indices = [random.choice(indices) for _ in range(count)]\n",
    "                    \n",
    "                    # Add duplicates\n",
    "                    for idx in duplicate_indices:\n",
    "                        train_texts.append(train_texts[idx])\n",
    "                        train_labels.append(train_labels[idx])\n",
    "        \n",
    "        # Create datasets and dataloaders\n",
    "        train_dataset = ANESDataset(train_texts, train_labels, tokenizer)\n",
    "        val_dataset = ANESDataset(val_texts, val_labels, tokenizer)\n",
    "        \n",
    "        # Use a smaller batch size if memory is an issue\n",
    "        batch_size = 16\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "        val_loader = DataLoader(val_dataset, batch_size=batch_size)\n",
    "\n",
    "        # Initialize model\n",
    "        num_labels = len(label_map)\n",
    "        model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=num_labels)\n",
    "        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        model.to(device)\n",
    "\n",
    "        # Compute class weights for handling imbalance\n",
    "        classes = np.unique(train_labels)\n",
    "        weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=train_labels)\n",
    "        weights_tensor = torch.tensor(weights, dtype=torch.float)\n",
    "        \n",
    "        # Create loss function with class weights\n",
    "        loss_fn = FocalLoss(alpha=weights_tensor, gamma=2.0)\n",
    "\n",
    "        # Optimizer and scheduler\n",
    "        optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "        total_steps = len(train_loader) * 4  # num_epochs = 4\n",
    "        scheduler = get_linear_schedule_with_warmup(\n",
    "            optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps\n",
    "        )\n",
    "\n",
    "        # Training loop\n",
    "        best_val_acc = 0\n",
    "        best_val_loss = float('inf')\n",
    "        best_model_state = None\n",
    "        \n",
    "        for epoch in range(1, 5):\n",
    "            print(f\"\\nEpoch {epoch}\")\n",
    "            train_loss, train_acc = train_epoch(model, train_loader, optimizer, scheduler, device, loss_fn)\n",
    "            val_loss, val_acc, val_logits, val_preds, val_labels = eval_epoch(model, val_loader, device, loss_fn)\n",
    "            print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "            print(f\"  Val   - Loss: {val_loss:.4f}, Acc: {val_acc:.4f}\")\n",
    "            \n",
    "            # Save best model\n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                best_val_loss = val_loss\n",
    "                best_model_state = model.state_dict().copy()\n",
    "        \n",
    "        # Load best model for evaluation\n",
    "        model.load_state_dict(best_model_state)\n",
    "        _, _, val_logits, val_preds, val_labels = eval_epoch(model, val_loader, device, loss_fn)\n",
    "        \n",
    "        # Evaluate with different thresholds\n",
    "        print(\"\\nEvaluating with different thresholds:\")\n",
    "        thresholds = [0.3, 0.4, 0.5, 0.6, 0.7]\n",
    "        for threshold in thresholds:\n",
    "            apply_threshold_and_report(val_logits, val_labels, label_map, threshold=threshold)\n",
    "        \n",
    "        # Save fold results\n",
    "        fold_results.append({\n",
    "            'val_acc': best_val_acc,\n",
    "            'val_loss': best_val_loss,\n",
    "            'val_logits': val_logits,\n",
    "            'val_labels': val_labels\n",
    "        })\n",
    "    \n",
    "    # Aggregate results across folds\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Cross-validation results:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    avg_acc = np.mean([res['val_acc'] for res in fold_results])\n",
    "    avg_loss = np.mean([res['val_loss'] for res in fold_results])\n",
    "    \n",
    "    print(f\"Average validation accuracy: {avg_acc:.4f}\")\n",
    "    print(f\"Average validation loss: {avg_loss:.4f}\")\n",
    "    \n",
    "    # Train final model on all data\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"Training final model on all data:\")\n",
    "    print(\"=\"*50)\n",
    "    \n",
    "    # Create datasets and dataloaders for full training\n",
    "    full_dataset = ANESDataset(texts, labels, tokenizer)\n",
    "    full_loader = DataLoader(full_dataset, batch_size=batch_size, shuffle=True)\n",
    "    \n",
    "    # Initialize final model\n",
    "    final_model = RobertaForSequenceClassification.from_pretrained(\"roberta-base\", num_labels=num_labels)\n",
    "    final_model.to(device)\n",
    "    \n",
    "    # Compute class weights for handling imbalance\n",
    "    classes = np.unique(labels)\n",
    "    weights = compute_class_weight(class_weight=\"balanced\", classes=classes, y=labels)\n",
    "    weights_tensor = torch.tensor(weights, dtype=torch.float)\n",
    "    \n",
    "    # Create loss function with class weights\n",
    "    loss_fn = FocalLoss(alpha=weights_tensor, gamma=2.0)\n",
    "    \n",
    "    # Optimizer and scheduler\n",
    "    optimizer = AdamW(final_model.parameters(), lr=2e-5)\n",
    "    total_steps = len(full_loader) * 4  # num_epochs = 4\n",
    "    scheduler = get_linear_schedule_with_warmup(\n",
    "        optimizer, num_warmup_steps=int(0.1 * total_steps), num_training_steps=total_steps\n",
    "    )\n",
    "    \n",
    "    # Training loop\n",
    "    for epoch in range(1, 5):\n",
    "        print(f\"\\nEpoch {epoch}\")\n",
    "        train_loss, train_acc = train_epoch(final_model, full_loader, optimizer, scheduler, device, loss_fn)\n",
    "        print(f\"  Train - Loss: {train_loss:.4f}, Acc: {train_acc:.4f}\")\n",
    "    \n",
    "    print(\"\\n‚úÖ Training completed.\")\n",
    "    \n",
    "    # Save the model\n",
    "    torch.save(final_model.state_dict(), 'anes_classifier_model_legitimate_features.pt')\n",
    "    print(\"\\nModel saved to 'anes_classifier_model_legitimate_features.pt'\")\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    # Replace with your data folder path\n",
    "    data_folder = \"/home/tsultanov/shared/datasets/respondents\"\n",
    "    \n",
    "    # Try different sampling strategies\n",
    "    for strategy in ['none', 'smote']:\n",
    "        print(f\"\\n{'='*70}\")\n",
    "        print(f\"Running with sampling strategy: {strategy}\")\n",
    "        print(f\"{'='*70}\")\n",
    "        main(data_folder, sampling_strategy=strategy)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
